{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf25339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from acquire import remove_stopwords, basic_clean, tokenize \n",
    "from prepare_jag import prep_train, basic_clean3\n",
    "import re\n",
    "from re import search\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e953a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test, notes, and features loaded.\n",
      "Merged dataframes\n",
      "Renamed 'pn_history' column to 'original'\n",
      "Added a basic clean column lowercaseing and removing special characters\n",
      "Added stemmed column with tokenized words and stopwords removed\n",
      "Added lemmatized column with lemmatized words and stopwords removed\n",
      "Data preparation complete\n"
     ]
    }
   ],
   "source": [
    "df = prep_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d5b62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>hpi 17yo presents palpitations patient reports...</td>\n",
       "      <td>hpi 17yo present palpit patient report 3-4 mon...</td>\n",
       "      <td>hpi 17yo present palpitation patient report 3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00041_000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>17 y/o came clinic c/o heart pounding started ...</td>\n",
       "      <td>17 y/o came clinic c/o heart pound start 2-3 m...</td>\n",
       "      <td>17 y/o came clinic c/o heart pounding started ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00046_000</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>['father: heart attack']</td>\n",
       "      <td>['824 844']</td>\n",
       "      <td>Mr. Cleveland is a 17yo M who was consented by...</td>\n",
       "      <td>mr cleveland 17yo consented parents alone toda...</td>\n",
       "      <td>mr cleveland 17yo wa consent parent alon today...</td>\n",
       "      <td>mr cleveland 17yo wa consented parent alone to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00082_000</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>['Father MI']</td>\n",
       "      <td>['622 631']</td>\n",
       "      <td>17 yo M w/ no cardiac or arrhythmia PMH presen...</td>\n",
       "      <td>17 yo w/ no cardiac arrhythmia pmh presents co...</td>\n",
       "      <td>17 yo w/ no cardiac arrhythmia pmh present com...</td>\n",
       "      <td>17 yo w/ no cardiac arrhythmia pmh present com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00100_000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>['Dad-MI']</td>\n",
       "      <td>['735 741']</td>\n",
       "      <td>HPI: Dillon Cleveland is an otherwise healthy ...</td>\n",
       "      <td>hpi dillon cleveland otherwise healthy 17 year...</td>\n",
       "      <td>hpi dillon cleveland otherwis healthi 17 year ...</td>\n",
       "      <td>hpi dillon cleveland otherwise healthy 17 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>95145_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95145</td>\n",
       "      <td>916</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>['subjective fever']</td>\n",
       "      <td>['169 185']</td>\n",
       "      <td>Pt is 20 yo F w headache since yesterday morni...</td>\n",
       "      <td>pt 20 yo f w headache since yesterday morning ...</td>\n",
       "      <td>pt 20 yo f w headach sinc yesterday morn pt st...</td>\n",
       "      <td>pt 20 yo f w headache since yesterday morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>95228_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95228</td>\n",
       "      <td>916</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>20 F no PMH, lives w/ roommate in apartment ha...</td>\n",
       "      <td>20 f no pmh lives w/ roommate apartment severe...</td>\n",
       "      <td>20 f no pmh live w/ roommat apart ha sever hea...</td>\n",
       "      <td>20 f no pmh life w/ roommate apartment ha seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>95243_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95243</td>\n",
       "      <td>916</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>['feels warm']</td>\n",
       "      <td>['376 386']</td>\n",
       "      <td>20 y/o F with no PMH is presenting with 1 day ...</td>\n",
       "      <td>20 y/o f no pmh presenting 1 day history heada...</td>\n",
       "      <td>20 y/o f no pmh present 1 day histori headach ...</td>\n",
       "      <td>20 y/o f no pmh presenting 1 day history heada...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>95330_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95330</td>\n",
       "      <td>916</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>['Felt warm']</td>\n",
       "      <td>['358 367']</td>\n",
       "      <td>Ms. Madden is a 20 yo female presenting w/ the...</td>\n",
       "      <td>ms madden 20 yo female presenting w/ worst ha ...</td>\n",
       "      <td>ms madden 20 yo femal present w/ worst ha life...</td>\n",
       "      <td>madden 20 yo female presenting w/ worst ha lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>95333_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>916</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>['Subjective fever']</td>\n",
       "      <td>['314 330']</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>stephanie madden 20 year old woman complaining...</td>\n",
       "      <td>stephani madden 20 year old woman complain hea...</td>\n",
       "      <td>stephanie madden 20 year old woman complaining...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14300 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  case_num  pn_num  feature_num  \\\n",
       "0      00016_000         0      16            0   \n",
       "1      00041_000         0      41            0   \n",
       "2      00046_000         0      46            0   \n",
       "3      00082_000         0      82            0   \n",
       "4      00100_000         0     100            0   \n",
       "...          ...       ...     ...          ...   \n",
       "14295  95145_916         9   95145          916   \n",
       "14296  95228_916         9   95228          916   \n",
       "14297  95243_916         9   95243          916   \n",
       "14298  95330_916         9   95330          916   \n",
       "14299  95333_916         9   95333          916   \n",
       "\n",
       "                                            feature_text  \\\n",
       "0      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "2      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "3      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "4      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "...                                                  ...   \n",
       "14295                                   Subjective-fever   \n",
       "14296                                   Subjective-fever   \n",
       "14297                                   Subjective-fever   \n",
       "14298                                   Subjective-fever   \n",
       "14299                                   Subjective-fever   \n",
       "\n",
       "                             annotation     location  \\\n",
       "0      ['dad with recent heart attcak']  ['696 724']   \n",
       "1                                    []           []   \n",
       "2              ['father: heart attack']  ['824 844']   \n",
       "3                         ['Father MI']  ['622 631']   \n",
       "4                            ['Dad-MI']  ['735 741']   \n",
       "...                                 ...          ...   \n",
       "14295              ['subjective fever']  ['169 185']   \n",
       "14296                                []           []   \n",
       "14297                    ['feels warm']  ['376 386']   \n",
       "14298                     ['Felt warm']  ['358 367']   \n",
       "14299              ['Subjective fever']  ['314 330']   \n",
       "\n",
       "                                                original  \\\n",
       "0      HPI: 17yo M presents with palpitations. Patien...   \n",
       "1      17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...   \n",
       "2      Mr. Cleveland is a 17yo M who was consented by...   \n",
       "3      17 yo M w/ no cardiac or arrhythmia PMH presen...   \n",
       "4      HPI: Dillon Cleveland is an otherwise healthy ...   \n",
       "...                                                  ...   \n",
       "14295  Pt is 20 yo F w headache since yesterday morni...   \n",
       "14296  20 F no PMH, lives w/ roommate in apartment ha...   \n",
       "14297  20 y/o F with no PMH is presenting with 1 day ...   \n",
       "14298  Ms. Madden is a 20 yo female presenting w/ the...   \n",
       "14299  Stephanie madden is a 20 year old woman compla...   \n",
       "\n",
       "                                                   clean  \\\n",
       "0      hpi 17yo presents palpitations patient reports...   \n",
       "1      17 y/o came clinic c/o heart pounding started ...   \n",
       "2      mr cleveland 17yo consented parents alone toda...   \n",
       "3      17 yo w/ no cardiac arrhythmia pmh presents co...   \n",
       "4      hpi dillon cleveland otherwise healthy 17 year...   \n",
       "...                                                  ...   \n",
       "14295  pt 20 yo f w headache since yesterday morning ...   \n",
       "14296  20 f no pmh lives w/ roommate apartment severe...   \n",
       "14297  20 y/o f no pmh presenting 1 day history heada...   \n",
       "14298  ms madden 20 yo female presenting w/ worst ha ...   \n",
       "14299  stephanie madden 20 year old woman complaining...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0      hpi 17yo present palpit patient report 3-4 mon...   \n",
       "1      17 y/o came clinic c/o heart pound start 2-3 m...   \n",
       "2      mr cleveland 17yo wa consent parent alon today...   \n",
       "3      17 yo w/ no cardiac arrhythmia pmh present com...   \n",
       "4      hpi dillon cleveland otherwis healthi 17 year ...   \n",
       "...                                                  ...   \n",
       "14295  pt 20 yo f w headach sinc yesterday morn pt st...   \n",
       "14296  20 f no pmh live w/ roommat apart ha sever hea...   \n",
       "14297  20 y/o f no pmh present 1 day histori headach ...   \n",
       "14298  ms madden 20 yo femal present w/ worst ha life...   \n",
       "14299  stephani madden 20 year old woman complain hea...   \n",
       "\n",
       "                                              lemmatized  \n",
       "0      hpi 17yo present palpitation patient report 3-...  \n",
       "1      17 y/o came clinic c/o heart pounding started ...  \n",
       "2      mr cleveland 17yo wa consented parent alone to...  \n",
       "3      17 yo w/ no cardiac arrhythmia pmh present com...  \n",
       "4      hpi dillon cleveland otherwise healthy 17 year...  \n",
       "...                                                  ...  \n",
       "14295  pt 20 yo f w headache since yesterday morning ...  \n",
       "14296  20 f no pmh life w/ roommate apartment ha seve...  \n",
       "14297  20 y/o f no pmh presenting 1 day history heada...  \n",
       "14298  madden 20 yo female presenting w/ worst ha lif...  \n",
       "14299  stephanie madden 20 year old woman complaining...  \n",
       "\n",
       "[14300 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce61be7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14300, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52db5d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hpi 17yo presents palpitations patient reports 3-4 months intermittent episodes heart beating/pounding chest 2 days ago soccer game episode time chest pressure felt going pass lose conciousness note patient endorses abusing adderall primarily study 1-3 times per week recent soccer game took adderrall night morning game denies shortness breath diaphoresis fevers chills headache fatigue changes sleep changes vision/hearing abdominal paun changes bowel urinary habits pmhx none rx uses friends adderrall fhx mom thyroid disease dad recent heart attcak none immunizations date shx freshmen college endorses 3-4 drinks 3 nights / week weekends denies tabacco endorses trying marijuana sexually active girlfriend x 1 year uses condoms'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992b7a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Family-history-of-MI-OR-Family-history-of-myocardial-infarction'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feature_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8993f",
   "metadata": {},
   "source": [
    "## Use stratified splits to ensure each case exists in the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb76d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 12870\n",
      "Number of rows in validation set: 715\n",
      "Number of rows in test set: 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.1\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=test_split, stratify=df['case_num'].values,\n",
    ")\n",
    "\n",
    "# Splitting the test set further into validation and new test set.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)\n",
    "\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d177ae2",
   "metadata": {},
   "source": [
    "## Multi-label binarization\n",
    "Let's preprocess our labels using the [StringLookup](https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup) layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd24a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.ragged.constant(train_df['feature_text'].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode='multi_hot')\n",
    "lookup.adapt(features)\n",
    "vocab = lookup.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61f1d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " 'Female',\n",
       " 'Male',\n",
       " '20-year',\n",
       " '17-year',\n",
       " '35-year',\n",
       " 'Nausea',\n",
       " 'symptoms-for-6-months',\n",
       " 'heart-pounding-OR-heart-racing',\n",
       " 'Episode-of-hand-numbness-OR-Episode-of-finger-numbness',\n",
       " 'Sleep-disturbance-OR-Early-awakenings',\n",
       " 'Post-prandial-bloating-OR-fullness-with-meals',\n",
       " 'No-vaginal-discharge',\n",
       " 'Minimal-to-no-change-with-Tums',\n",
       " 'Heavy-sweating',\n",
       " 'FHx-of-depression-OR-Family-history-of-depression',\n",
       " 'getting-worse-OR-progressive-OR-symptoms-now-daily',\n",
       " 'Unprotected-Sex',\n",
       " 'Stress-due-to-caring-for-elderly-parents',\n",
       " 'Son-died-3-weeks-ago',\n",
       " 'Recurrent-bouts-over-past-6-months',\n",
       " 'No-urinary-symptoms',\n",
       " 'No-chest-pain',\n",
       " 'Intermittent-symptoms',\n",
       " 'Feels-hot-OR-Feels-clammy',\n",
       " 'Episodes-last-15-to-30-minutes',\n",
       " 'Diminished-energy-OR-feeling-drained',\n",
       " 'Decreased-appetite',\n",
       " '8-to-10-hours-of-acute-pain',\n",
       " 'Weight-Gain',\n",
       " 'Vomiting',\n",
       " 'Visual-hallucination-once',\n",
       " 'Stress',\n",
       " 'Recent-nausea-vomiting-OR-Recent-flulike-symptoms',\n",
       " 'No-suicidal-ideations',\n",
       " 'No-relief-with-asthma-inhaler',\n",
       " 'No-illicit-drug-use',\n",
       " 'Epigastric-discomfort',\n",
       " 'Difficulty-with-sleep',\n",
       " 'Caffeine-use',\n",
       " 'Auditory-hallucination-once',\n",
       " 'Associated-feeling-of-impending-doom',\n",
       " 'Subjective-fever',\n",
       " 'Sleeping-medication-ineffective',\n",
       " 'Sharp-OR-stabbing-OR-7-to-8-out-of-10-on-pain-scale',\n",
       " 'Photophobia',\n",
       " 'No-premenstrual-symptoms',\n",
       " 'No-blood-in-stool',\n",
       " 'Lightheaded',\n",
       " 'LMP-2-months-ago-or-Last-menstrual-period-2-months-ago',\n",
       " 'Insomnia',\n",
       " 'Increased-appetite',\n",
       " 'Hallucinations-after-taking-Ambien',\n",
       " 'Family-history-of-thyroid-disorder',\n",
       " 'Exercise-induced-asthma',\n",
       " 'Chest-pressure',\n",
       " '2-to-3-beers-a-week',\n",
       " '1-day-duration-OR-2-days-duration',\n",
       " 'viral-symptoms-OR-rhinorrhea-OR-scratchy-throat',\n",
       " 'burning-OR-gnawing-OR-burning-and-gnawing',\n",
       " 'Worse-with-deep-breath-OR-pleuritic',\n",
       " 'Recent-visit-to-emergency-department-with-negative-workup',\n",
       " 'Recent-upper-respiratory-symptoms',\n",
       " 'Not-sexually-active',\n",
       " 'Normal-LMP-2-weeks-ago-OR-Normal-last-menstrual-period-2-weeks-ago',\n",
       " 'No-rash',\n",
       " 'No-caffeine-use',\n",
       " 'Neck-pain',\n",
       " 'Lack-of-other-thyroid-symptoms',\n",
       " 'Infertility-HX-OR-Infertility-history',\n",
       " 'Hot-flashes',\n",
       " 'Global-headache-OR-diffuse-headache',\n",
       " 'Family-history-of-migraines',\n",
       " 'Early-wakening',\n",
       " 'Diminished-appetite',\n",
       " 'Associated-throat-tightness',\n",
       " '45-year',\n",
       " '44-year',\n",
       " 'loss-of-interest',\n",
       " 'duration-2-months',\n",
       " 'anxious-OR-nervous',\n",
       " 'Weight-loss',\n",
       " 'Sexually-active',\n",
       " 'Onset-5-years-ago',\n",
       " 'Onset-3-years-ago',\n",
       " 'No-relief-with-Motrin-OR-no-relief-with-tylenol',\n",
       " 'No-known-illness-contacts',\n",
       " 'No-depressed-mood',\n",
       " 'NSAID-use-OR-Nonsteroidal-anti-inflammatory-drug-use',\n",
       " 'Meningococcal-vaccine-status-unknown',\n",
       " 'Irregular-flow-OR-Irregular-frequency-OR-Irregular-intervals',\n",
       " 'Intermittent',\n",
       " 'IUD',\n",
       " 'Heavy-caffeine-use',\n",
       " 'Fatigue-OR-Difficulty-concentrating',\n",
       " 'Family-history-of-MI-OR-Family-history-of-myocardial-infarction',\n",
       " 'Duration-x-1-day',\n",
       " 'Associated-nausea',\n",
       " 'Adderall-use',\n",
       " '26-year',\n",
       " 'tossing-and-turning',\n",
       " 'Vaginal-dryness',\n",
       " 'Unsuccessful-napping',\n",
       " 'Subjective-fevers',\n",
       " 'Shortness-of-breath',\n",
       " 'Recent-heavy-lifting-at-work-OR-recent-rock-climbing',\n",
       " 'Last-menstrual-period-2-months-ago',\n",
       " 'Last-Pap-smear-I-year-ago',\n",
       " 'Few-months-duration',\n",
       " 'Associated-SOB-OR-Associated-shortness-of-breath',\n",
       " 'Weight-stable',\n",
       " 'Prior-normal-periods',\n",
       " 'Prior-episodes-of-diarrhea',\n",
       " 'No-shortness-of-breath',\n",
       " 'Myalgias',\n",
       " 'Irregular-menses',\n",
       " 'Fatigue',\n",
       " 'FHx-of-PUD-OR-Family-history-of-peptic-ulcer-disease',\n",
       " 'Difficulty-falling-asleep',\n",
       " 'Chest-pain',\n",
       " 'Awakens-at-night',\n",
       " 'heavy-periods-OR-irregular-periods',\n",
       " 'Shares-an-apartment',\n",
       " 'No-bloody-bowel-movements',\n",
       " 'Increased-stress',\n",
       " '67-year',\n",
       " 'Episodes-of-heart-racing',\n",
       " 'duration-3-weeks',\n",
       " 'Right-sided-LQ-abdominal-pain-OR-Right-lower-quadrant-abdominal-pain',\n",
       " 'Increased-frequency-recently',\n",
       " 'Darker-bowel-movements',\n",
       " 'No-hair-changes-OR-no-nail-changes-OR-no-temperature-intolerance']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1951acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['[UNK]', 'Female', 'Male', '20-year', '17-year', '35-year', 'Nausea', 'symptoms-for-6-months', 'heart-pounding-OR-heart-racing', 'Episode-of-hand-numbness-OR-Episode-of-finger-numbness', 'Sleep-disturbance-OR-Early-awakenings', 'Post-prandial-bloating-OR-fullness-with-meals', 'No-vaginal-discharge', 'Minimal-to-no-change-with-Tums', 'Heavy-sweating', 'FHx-of-depression-OR-Family-history-of-depression', 'getting-worse-OR-progressive-OR-symptoms-now-daily', 'Unprotected-Sex', 'Stress-due-to-caring-for-elderly-parents', 'Son-died-3-weeks-ago', 'Recurrent-bouts-over-past-6-months', 'No-urinary-symptoms', 'No-chest-pain', 'Intermittent-symptoms', 'Feels-hot-OR-Feels-clammy', 'Episodes-last-15-to-30-minutes', 'Diminished-energy-OR-feeling-drained', 'Decreased-appetite', '8-to-10-hours-of-acute-pain', 'Weight-Gain', 'Vomiting', 'Visual-hallucination-once', 'Stress', 'Recent-nausea-vomiting-OR-Recent-flulike-symptoms', 'No-suicidal-ideations', 'No-relief-with-asthma-inhaler', 'No-illicit-drug-use', 'Epigastric-discomfort', 'Difficulty-with-sleep', 'Caffeine-use', 'Auditory-hallucination-once', 'Associated-feeling-of-impending-doom', 'Subjective-fever', 'Sleeping-medication-ineffective', 'Sharp-OR-stabbing-OR-7-to-8-out-of-10-on-pain-scale', 'Photophobia', 'No-premenstrual-symptoms', 'No-blood-in-stool', 'Lightheaded', 'LMP-2-months-ago-or-Last-menstrual-period-2-months-ago', 'Insomnia', 'Increased-appetite', 'Hallucinations-after-taking-Ambien', 'Family-history-of-thyroid-disorder', 'Exercise-induced-asthma', 'Chest-pressure', '2-to-3-beers-a-week', '1-day-duration-OR-2-days-duration', 'viral-symptoms-OR-rhinorrhea-OR-scratchy-throat', 'burning-OR-gnawing-OR-burning-and-gnawing', 'Worse-with-deep-breath-OR-pleuritic', 'Recent-visit-to-emergency-department-with-negative-workup', 'Recent-upper-respiratory-symptoms', 'Not-sexually-active', 'Normal-LMP-2-weeks-ago-OR-Normal-last-menstrual-period-2-weeks-ago', 'No-rash', 'No-caffeine-use', 'Neck-pain', 'Lack-of-other-thyroid-symptoms', 'Infertility-HX-OR-Infertility-history', 'Hot-flashes', 'Global-headache-OR-diffuse-headache', 'Family-history-of-migraines', 'Early-wakening', 'Diminished-appetite', 'Associated-throat-tightness', '45-year', '44-year', 'loss-of-interest', 'duration-2-months', 'anxious-OR-nervous', 'Weight-loss', 'Sexually-active', 'Onset-5-years-ago', 'Onset-3-years-ago', 'No-relief-with-Motrin-OR-no-relief-with-tylenol', 'No-known-illness-contacts', 'No-depressed-mood', 'NSAID-use-OR-Nonsteroidal-anti-inflammatory-drug-use', 'Meningococcal-vaccine-status-unknown', 'Irregular-flow-OR-Irregular-frequency-OR-Irregular-intervals', 'Intermittent', 'IUD', 'Heavy-caffeine-use', 'Fatigue-OR-Difficulty-concentrating', 'Family-history-of-MI-OR-Family-history-of-myocardial-infarction', 'Duration-x-1-day', 'Associated-nausea', 'Adderall-use', '26-year', 'tossing-and-turning', 'Vaginal-dryness', 'Unsuccessful-napping', 'Subjective-fevers', 'Shortness-of-breath', 'Recent-heavy-lifting-at-work-OR-recent-rock-climbing', 'Last-menstrual-period-2-months-ago', 'Last-Pap-smear-I-year-ago', 'Few-months-duration', 'Associated-SOB-OR-Associated-shortness-of-breath', 'Weight-stable', 'Prior-normal-periods', 'Prior-episodes-of-diarrhea', 'No-shortness-of-breath', 'Myalgias', 'Irregular-menses', 'Fatigue', 'FHx-of-PUD-OR-Family-history-of-peptic-ulcer-disease', 'Difficulty-falling-asleep', 'Chest-pain', 'Awakens-at-night', 'heavy-periods-OR-irregular-periods', 'Shares-an-apartment', 'No-bloody-bowel-movements', 'Increased-stress', '67-year', 'Episodes-of-heart-racing', 'duration-3-weeks', 'Right-sided-LQ-abdominal-pain-OR-Right-lower-quadrant-abdominal-pain', 'Increased-frequency-recently', 'Darker-bowel-movements', 'No-hair-changes-OR-no-nail-changes-OR-no-temperature-intolerance']\n"
     ]
    }
   ],
   "source": [
    "def invert_multi_hot(encoded_labels):\n",
    "    '''Reverse a single multi-hot encoded label to a tuple of vocab terms.'''\n",
    "    hot_indices = np.argwhere(encoded_labels == 1.0)[...,0]\n",
    "    return np.take(vocab, hot_indices)\n",
    "\n",
    "print('Vocabulary:\\n')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47645f85",
   "metadata": {},
   "source": [
    "### Separate the individual targets from the label pool and then use it to represent a given label set with 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b4af335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: Adderall-use\n",
      "Label-binarized representation: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "sample_label = train_df['feature_text'].iloc[0]\n",
    "print(f'Original label: {sample_label}')\n",
    "\n",
    "label_binarized = lookup([sample_label])\n",
    "print(f'Label-binarized representation: {label_binarized}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1776c2",
   "metadata": {},
   "source": [
    "## Data preprocessing and [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48b7086c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12870.000000\n",
       "mean        96.436519\n",
       "std         16.034076\n",
       "min         26.000000\n",
       "25%         87.000000\n",
       "50%         98.000000\n",
       "75%        108.000000\n",
       "max        134.000000\n",
       "Name: clean, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean'].apply(lambda x: len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb41f8",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "* Half of the student notes have a length of 97 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44dac1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 97\n",
    "batch_size = 128\n",
    "padding_token = '<pad>'\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe['feature_text'].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe['clean'].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a09421",
   "metadata": {},
   "source": [
    "## Prepare the [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f16e6859",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 12870 and 132 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jl/s3ptdwdx55v01d2g2wrs7vdc0000gn/T/ipykernel_34480/752064178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jl/s3ptdwdx55v01d2g2wrs7vdc0000gn/T/ipykernel_34480/3097679748.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(dataframe, is_train)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabel_binarized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     dataset = tf.data.Dataset.from_tensor_slices(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_binarized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m     \"\"\"\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4489\u001b[0m         tensor_shape.dimension_value(self._tensors[0].get_shape()[0]))\n\u001b[1;32m   4490\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4491\u001b[0;31m       batch_dim.assert_is_compatible_with(\n\u001b[0m\u001b[1;32m   4492\u001b[0m           tensor_shape.Dimension(\n\u001b[1;32m   4493\u001b[0m               tensor_shape.dimension_value(t.get_shape()[0])))\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0m\u001b[1;32m    295\u001b[0m                        (self, other))\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 12870 and 132 are not compatible"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e592805",
   "metadata": {},
   "source": [
    "## Preview the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d92419",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f'Student note: {text}')\n",
    "    print(f'Targets: {invert_multi_hot(label[0])}')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ce7d3",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "Vectorize the text to represent it as a quantitative value. We will use [TextVectorization layer](https://keras.io/api/layers/preprocessing_layers/text/text_vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39597f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6723\n"
     ]
    }
   ],
   "source": [
    "# Get unique words in student notes.\n",
    "vocabulary = set()\n",
    "train_df['clean'].str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37594eb7",
   "metadata": {},
   "source": [
    "## Now we create our vectorization layer and map() to the [tf.data.Datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00403449",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jl/s3ptdwdx55v01d2g2wrs7vdc0000gn/T/ipykernel_34480/2775773759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/CPU:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtext_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m train_dataset = train_dataset.map(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, ngrams=2, output_mode='tf_idf'\n",
    ")\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda test, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c175f",
   "metadata": {},
   "source": [
    "## Create a text classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e576f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(512, activation=\"relu\"),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"softmax\"),\n",
    "        ]  # More on why \"sigmoid\" has been used here in a moment.\n",
    "    )\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c18c4",
   "metadata": {},
   "source": [
    "## Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "history = shallow_mlp_model.fit(\n",
    "    train_dataset, validation_data=validation_dataset, epochs=epochs\n",
    ")\n",
    "\n",
    "\n",
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b02c7",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, categorical_acc = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Categorical accuracy on the test set: {round(categorical_acc * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd36a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for inference.\n",
    "model_for_inference = keras.Sequential([text_vectorizer, shallow_mlp_model])\n",
    "\n",
    "# Create a small dataset just for demoing inference.\n",
    "inference_dataset = make_dataset(test_df.sample(100), is_train=False)\n",
    "text_batch, label_batch = next(iter(inference_dataset))\n",
    "predicted_probabilities = model_for_inference.predict(text_batch)\n",
    "\n",
    "# Perform inference.\n",
    "for i, text in enumerate(text_batch[10:50]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Student notes: {text}\")\n",
    "    print(f\"Targets(s): {invert_multi_hot(label[0])}\")\n",
    "    predicted_proba = [proba for proba in predicted_probabilities[i]]\n",
    "    all_labels = [\n",
    "        x\n",
    "        for _, x in sorted(\n",
    "            zip(predicted_probabilities[i], lookup.get_vocabulary()),\n",
    "            key=lambda pair: pair[0],\n",
    "            reverse=True,\n",
    "            \n",
    "        )\n",
    "    ][:]\n",
    "    print(f\"Predicted Targets(s): ({', '.join([label for label in all_labels])})\")\n",
    "    print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
