{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from time import strftime\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import acquire\n",
    "\n",
    "import spacy\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import prepare_jag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the 1000 labeled notes in `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'pn_history' column to 'original'\n",
      "Added a basic clean column lowercaseing and removing special characters\n",
      "Added stemmed column with tokenized words and stopwords removed\n",
      "Added lemmatized column with lemmatized words and stopwords removed\n",
      "Data preparation complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num_x</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>case_num_y</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>['dad with recent heart attcak']</td>\n",
       "      <td>['696 724']</td>\n",
       "      <td>0</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \\r\\nPMHx: none\\r\\nRx: uses friends adderrall\\r\\nFHx: mom with \"thyroid disease,\" dad with recent heart attcak\\r\\nAll: none\\r\\nImmunizations: up to date\\r\\nSHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms</td>\n",
       "      <td>hpi 17yo presents palpitations patient reports 34 months intermittent episodes heart beatingpounding chest 2 days ago soccer game episode time chest pressure felt going pass lose conciousness note patient endorses abusing adderall primarily study 13 times per week recent soccer game took adderrall night morning game denies shortness breath diaphoresis fevers chills headache fatigue changes sleep changes visionhearing abdominal paun changes bowel urinary habits pmhx none rx uses friends adderrall fhx mom thyroid disease dad recent heart attcak none immunizations date shx freshmen college endorses 34 drinks 3 nights week weekends denies tabacco endorses trying marijuana sexually active girlfriend x 1 year uses condoms</td>\n",
       "      <td>hpi 17yo present palpit patient report 34 month intermitt episod heart beatingpound chest 2 day ago dure soccer game episod thi time chest pressur felt go pass lose concious note patient endors abus adderal primarili studi 13 time per week befor recent soccer game took adderral night befor morn game deni short breath diaphoresi fever chill headach fatigu chang sleep chang visionhear abdomin paun chang bowel urinari habit pmhx none rx use friend adderral fhx mom thyroid diseas dad recent heart attcak none immun date shx freshmen colleg endors 34 drink 3 night week weekend deni tabacco endors tri marijuana sexual activ girlfriend x 1 year use condom</td>\n",
       "      <td>hpi 17yo present palpitation patient report 34 month intermittent episode heart beatingpounding chest 2 day ago soccer game episode time chest pressure felt going pas lose conciousness note patient endorses abusing adderall primarily study 13 time per week recent soccer game took adderrall night morning game denies shortness breath diaphoresis fever chill headache fatigue change sleep change visionhearing abdominal paun change bowel urinary habit pmhx none rx us friend adderrall fhx mom thyroid disease dad recent heart attcak none immunization date shx freshman college endorses 34 drink 3 night week weekend denies tabacco endorses trying marijuana sexually active girlfriend x 1 year us condom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num_x  pn_num  feature_num  \\\n",
       "0  00016_000           0      16            0   \n",
       "\n",
       "                         annotation     location  case_num_y  \\\n",
       "0  ['dad with recent heart attcak']  ['696 724']           0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 original  \\\n",
       "0  HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \\r\\nPMHx: none\\r\\nRx: uses friends adderrall\\r\\nFHx: mom with \"thyroid disease,\" dad with recent heart attcak\\r\\nAll: none\\r\\nImmunizations: up to date\\r\\nSHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   clean  \\\n",
       "0  hpi 17yo presents palpitations patient reports 34 months intermittent episodes heart beatingpounding chest 2 days ago soccer game episode time chest pressure felt going pass lose conciousness note patient endorses abusing adderall primarily study 13 times per week recent soccer game took adderrall night morning game denies shortness breath diaphoresis fevers chills headache fatigue changes sleep changes visionhearing abdominal paun changes bowel urinary habits pmhx none rx uses friends adderrall fhx mom thyroid disease dad recent heart attcak none immunizations date shx freshmen college endorses 34 drinks 3 nights week weekends denies tabacco endorses trying marijuana sexually active girlfriend x 1 year uses condoms   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           stemmed  \\\n",
       "0  hpi 17yo present palpit patient report 34 month intermitt episod heart beatingpound chest 2 day ago dure soccer game episod thi time chest pressur felt go pass lose concious note patient endors abus adderal primarili studi 13 time per week befor recent soccer game took adderral night befor morn game deni short breath diaphoresi fever chill headach fatigu chang sleep chang visionhear abdomin paun chang bowel urinari habit pmhx none rx use friend adderral fhx mom thyroid diseas dad recent heart attcak none immun date shx freshmen colleg endors 34 drink 3 night week weekend deni tabacco endors tri marijuana sexual activ girlfriend x 1 year use condom   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      lemmatized  \n",
       "0  hpi 17yo present palpitation patient report 34 month intermittent episode heart beatingpounding chest 2 day ago soccer game episode time chest pressure felt going pas lose conciousness note patient endorses abusing adderall primarily study 13 time per week recent soccer game took adderrall night morning game denies shortness breath diaphoresis fever chill headache fatigue change sleep change visionhearing abdominal paun change bowel urinary habit pmhx none rx us friend adderrall fhx mom thyroid disease dad recent heart attcak none immunization date shx freshman college endorses 34 drink 3 night week weekend denies tabacco endorses trying marijuana sexually active girlfriend x 1 year us condom  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data labels and merge on notes\n",
    "df = pd.read_csv('train.csv')\n",
    "notes = pd.read_csv('patient_notes.csv')\n",
    "df = df.merge(notes, how='inner', on='pn_num')\n",
    "df.rename(columns={'pn_history': 'original'}, inplace=True)\n",
    "df = prepare_jag.prep_article_data(df, 'original', extra_words=[], exclude_words=['no'])\n",
    "\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X is lemmatized text\n",
    "- y is feature number\n",
    "- convert y to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X Y\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.lemmatized)\n",
    "y = df.feature_num.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      100\n",
       "611    100\n",
       "605    100\n",
       "606    100\n",
       "607    100\n",
       "      ... \n",
       "305    100\n",
       "306    100\n",
       "307    100\n",
       "308    100\n",
       "916    100\n",
       "Name: feature_num, Length: 143, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feature_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features appear to be equally represented, so pick any one fot baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.006993\n",
       "Name: feature_num, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "df[df['feature_num'] == 0].feature_num.value_counts()/sum(df.feature_num.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline is 0.70%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create evaluation dataframe\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "train['baseline']='11'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.actual = train.actual.astype('category')\n",
    "train.baseline = train.baseline.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544       11\n",
       "2856     201\n",
       "1371     106\n",
       "11268    800\n",
       "7986     506\n",
       "        ... \n",
       "10029    703\n",
       "7847     511\n",
       "3222     210\n",
       "6862     402\n",
       "9819     603\n",
       "Name: feature_num, Length: 11440, dtype: category\n",
       "Categories (143, int64): [0, 1, 2, 3, ..., 913, 914, 915, 916]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>201</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>106</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>800</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>506</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual baseline\n",
       "544       11       11\n",
       "2856     201       11\n",
       "1371     106       11\n",
       "11268    800       11\n",
       "7986     506       11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual      category\n",
       "baseline    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70%\n",
      "---\n",
      "Confusion Matrix\n",
      "baseline  11\n",
      "actual      \n",
      "0         80\n",
      "1         80\n",
      "2         80\n",
      "3         80\n",
      "4         80\n",
      "...       ..\n",
      "912       80\n",
      "913       80\n",
      "914       80\n",
      "915       80\n",
      "916       80\n",
      "\n",
      "[143 rows x 1 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00        80\n",
      "           2       0.00      0.00      0.00        80\n",
      "           3       0.00      0.00      0.00        80\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00        80\n",
      "           6       0.00      0.00      0.00        80\n",
      "           7       0.00      0.00      0.00        80\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        80\n",
      "          10       0.00      0.00      0.00        80\n",
      "          11       0.01      1.00      0.01        80\n",
      "          12       0.00      0.00      0.00        80\n",
      "         100       0.00      0.00      0.00        80\n",
      "         101       0.00      0.00      0.00        80\n",
      "         102       0.00      0.00      0.00        80\n",
      "         103       0.00      0.00      0.00        80\n",
      "         104       0.00      0.00      0.00        80\n",
      "         105       0.00      0.00      0.00        80\n",
      "         106       0.00      0.00      0.00        80\n",
      "         107       0.00      0.00      0.00        80\n",
      "         108       0.00      0.00      0.00        80\n",
      "         109       0.00      0.00      0.00        80\n",
      "         110       0.00      0.00      0.00        80\n",
      "         111       0.00      0.00      0.00        80\n",
      "         112       0.00      0.00      0.00        80\n",
      "         200       0.00      0.00      0.00        80\n",
      "         201       0.00      0.00      0.00        80\n",
      "         202       0.00      0.00      0.00        80\n",
      "         203       0.00      0.00      0.00        80\n",
      "         204       0.00      0.00      0.00        80\n",
      "         205       0.00      0.00      0.00        80\n",
      "         206       0.00      0.00      0.00        80\n",
      "         207       0.00      0.00      0.00        80\n",
      "         208       0.00      0.00      0.00        80\n",
      "         209       0.00      0.00      0.00        80\n",
      "         210       0.00      0.00      0.00        80\n",
      "         211       0.00      0.00      0.00        80\n",
      "         212       0.00      0.00      0.00        80\n",
      "         213       0.00      0.00      0.00        80\n",
      "         214       0.00      0.00      0.00        80\n",
      "         215       0.00      0.00      0.00        80\n",
      "         216       0.00      0.00      0.00        80\n",
      "         300       0.00      0.00      0.00        80\n",
      "         301       0.00      0.00      0.00        80\n",
      "         302       0.00      0.00      0.00        80\n",
      "         303       0.00      0.00      0.00        80\n",
      "         304       0.00      0.00      0.00        80\n",
      "         305       0.00      0.00      0.00        80\n",
      "         306       0.00      0.00      0.00        80\n",
      "         307       0.00      0.00      0.00        80\n",
      "         308       0.00      0.00      0.00        80\n",
      "         309       0.00      0.00      0.00        80\n",
      "         310       0.00      0.00      0.00        80\n",
      "         311       0.00      0.00      0.00        80\n",
      "         312       0.00      0.00      0.00        80\n",
      "         313       0.00      0.00      0.00        80\n",
      "         314       0.00      0.00      0.00        80\n",
      "         315       0.00      0.00      0.00        80\n",
      "         400       0.00      0.00      0.00        80\n",
      "         401       0.00      0.00      0.00        80\n",
      "         402       0.00      0.00      0.00        80\n",
      "         403       0.00      0.00      0.00        80\n",
      "         404       0.00      0.00      0.00        80\n",
      "         405       0.00      0.00      0.00        80\n",
      "         406       0.00      0.00      0.00        80\n",
      "         407       0.00      0.00      0.00        80\n",
      "         408       0.00      0.00      0.00        80\n",
      "         409       0.00      0.00      0.00        80\n",
      "         500       0.00      0.00      0.00        80\n",
      "         501       0.00      0.00      0.00        80\n",
      "         502       0.00      0.00      0.00        80\n",
      "         503       0.00      0.00      0.00        80\n",
      "         504       0.00      0.00      0.00        80\n",
      "         505       0.00      0.00      0.00        80\n",
      "         506       0.00      0.00      0.00        80\n",
      "         507       0.00      0.00      0.00        80\n",
      "         508       0.00      0.00      0.00        80\n",
      "         509       0.00      0.00      0.00        80\n",
      "         510       0.00      0.00      0.00        80\n",
      "         511       0.00      0.00      0.00        80\n",
      "         512       0.00      0.00      0.00        80\n",
      "         513       0.00      0.00      0.00        80\n",
      "         514       0.00      0.00      0.00        80\n",
      "         515       0.00      0.00      0.00        80\n",
      "         516       0.00      0.00      0.00        80\n",
      "         517       0.00      0.00      0.00        80\n",
      "         600       0.00      0.00      0.00        80\n",
      "         601       0.00      0.00      0.00        80\n",
      "         602       0.00      0.00      0.00        80\n",
      "         603       0.00      0.00      0.00        80\n",
      "         604       0.00      0.00      0.00        80\n",
      "         605       0.00      0.00      0.00        80\n",
      "         606       0.00      0.00      0.00        80\n",
      "         607       0.00      0.00      0.00        80\n",
      "         608       0.00      0.00      0.00        80\n",
      "         609       0.00      0.00      0.00        80\n",
      "         610       0.00      0.00      0.00        80\n",
      "         611       0.00      0.00      0.00        80\n",
      "         700       0.00      0.00      0.00        80\n",
      "         701       0.00      0.00      0.00        80\n",
      "         702       0.00      0.00      0.00        80\n",
      "         703       0.00      0.00      0.00        80\n",
      "         704       0.00      0.00      0.00        80\n",
      "         705       0.00      0.00      0.00        80\n",
      "         706       0.00      0.00      0.00        80\n",
      "         707       0.00      0.00      0.00        80\n",
      "         708       0.00      0.00      0.00        80\n",
      "         800       0.00      0.00      0.00        80\n",
      "         801       0.00      0.00      0.00        80\n",
      "         802       0.00      0.00      0.00        80\n",
      "         803       0.00      0.00      0.00        80\n",
      "         804       0.00      0.00      0.00        80\n",
      "         805       0.00      0.00      0.00        80\n",
      "         806       0.00      0.00      0.00        80\n",
      "         807       0.00      0.00      0.00        80\n",
      "         808       0.00      0.00      0.00        80\n",
      "         809       0.00      0.00      0.00        80\n",
      "         810       0.00      0.00      0.00        80\n",
      "         811       0.00      0.00      0.00        80\n",
      "         812       0.00      0.00      0.00        80\n",
      "         813       0.00      0.00      0.00        80\n",
      "         814       0.00      0.00      0.00        80\n",
      "         815       0.00      0.00      0.00        80\n",
      "         816       0.00      0.00      0.00        80\n",
      "         817       0.00      0.00      0.00        80\n",
      "         900       0.00      0.00      0.00        80\n",
      "         901       0.00      0.00      0.00        80\n",
      "         902       0.00      0.00      0.00        80\n",
      "         903       0.00      0.00      0.00        80\n",
      "         904       0.00      0.00      0.00        80\n",
      "         905       0.00      0.00      0.00        80\n",
      "         906       0.00      0.00      0.00        80\n",
      "         907       0.00      0.00      0.00        80\n",
      "         908       0.00      0.00      0.00        80\n",
      "         909       0.00      0.00      0.00        80\n",
      "         910       0.00      0.00      0.00        80\n",
      "         911       0.00      0.00      0.00        80\n",
      "         912       0.00      0.00      0.00        80\n",
      "         913       0.00      0.00      0.00        80\n",
      "         914       0.00      0.00      0.00        80\n",
      "         915       0.00      0.00      0.00        80\n",
      "         916       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.01     11440\n",
      "   macro avg       0.00      0.01      0.00     11440\n",
      "weighted avg       0.00      0.01      0.00     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline model performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.baseline)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.actual, train.baseline))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544       11\n",
       "2856     201\n",
       "1371     106\n",
       "11268    800\n",
       "7986     506\n",
       "        ... \n",
       "10029    703\n",
       "7847     511\n",
       "3222     210\n",
       "6862     402\n",
       "9819     603\n",
       "Name: feature_num, Length: 11440, dtype: category\n",
       "Categories (143, int64): [0, 1, 2, 3, ..., 913, 914, 915, 916]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         0  1   2   3   4   5   6   7   8   9  ...  907  908  909  910  \\\n",
      "lm_predicted                                         ...                       \n",
      "0             10  5   8   7   6   9  10  10  10   7  ...    0    0    0    0   \n",
      "1              4  7   5   6   5   6   6   7   5   5  ...    0    0    0    0   \n",
      "2              5  4   5   4   4   3   3   4   3   2  ...    0    0    0    0   \n",
      "3              9  7   8  11  10   9   9   7   6   8  ...    0    0    0    0   \n",
      "4              7  9  11   8  13  10  13  11  12  12  ...    0    0    0    0   \n",
      "...           .. ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
      "912            0  0   0   0   0   0   0   0   0   0  ...    4    5    6    4   \n",
      "913            0  0   0   0   0   0   0   0   0   0  ...    8    9   10   10   \n",
      "914            0  0   0   0   0   0   0   0   0   0  ...    3    4    3    4   \n",
      "915            0  0   0   0   0   0   0   0   0   0  ...    6    7    6    5   \n",
      "916            0  0   0   0   0   0   0   0   0   0  ...    6    7    5    5   \n",
      "\n",
      "actual        911  912  913  914  915  916  \n",
      "lm_predicted                                \n",
      "0               0    0    0    0    0    0  \n",
      "1               0    0    0    0    0    0  \n",
      "2               0    0    0    0    0    0  \n",
      "3               0    0    0    0    0    0  \n",
      "4               0    0    0    0    0    0  \n",
      "...           ...  ...  ...  ...  ...  ...  \n",
      "912             5    7    5    3    7    4  \n",
      "913             9    9   11    8    7    8  \n",
      "914             4    4    4    5    5    4  \n",
      "915             6    6    4    5    7    6  \n",
      "916             6    5    2    6    5    7  \n",
      "\n",
      "[143 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.12      0.11        80\n",
      "           1       0.10      0.09      0.09        80\n",
      "           2       0.10      0.06      0.08        80\n",
      "           3       0.10      0.14      0.12        80\n",
      "           4       0.10      0.16      0.12        80\n",
      "           5       0.10      0.05      0.07        80\n",
      "           6       0.09      0.11      0.10        80\n",
      "           7       0.10      0.07      0.08        80\n",
      "           8       0.10      0.04      0.05        80\n",
      "           9       0.09      0.09      0.09        80\n",
      "          10       0.09      0.11      0.10        80\n",
      "          11       0.10      0.14      0.11        80\n",
      "          12       0.09      0.06      0.07        80\n",
      "         100       0.10      0.20      0.13        80\n",
      "         101       0.10      0.14      0.12        80\n",
      "         102       0.10      0.05      0.07        80\n",
      "         103       0.09      0.06      0.08        80\n",
      "         104       0.10      0.05      0.07        80\n",
      "         105       0.09      0.10      0.10        80\n",
      "         106       0.09      0.11      0.10        80\n",
      "         107       0.09      0.05      0.06        80\n",
      "         108       0.09      0.11      0.10        80\n",
      "         109       0.11      0.04      0.06        80\n",
      "         110       0.09      0.11      0.10        80\n",
      "         111       0.10      0.10      0.10        80\n",
      "         112       0.10      0.12      0.11        80\n",
      "         200       0.07      0.05      0.06        80\n",
      "         201       0.07      0.09      0.08        80\n",
      "         202       0.08      0.09      0.08        80\n",
      "         203       0.08      0.09      0.08        80\n",
      "         204       0.07      0.04      0.05        80\n",
      "         205       0.07      0.07      0.07        80\n",
      "         206       0.07      0.06      0.07        80\n",
      "         207       0.07      0.06      0.07        80\n",
      "         208       0.08      0.09      0.08        80\n",
      "         209       0.08      0.09      0.08        80\n",
      "         210       0.08      0.07      0.08        80\n",
      "         211       0.07      0.07      0.07        80\n",
      "         212       0.07      0.10      0.08        80\n",
      "         213       0.07      0.06      0.07        80\n",
      "         214       0.07      0.06      0.07        80\n",
      "         215       0.08      0.05      0.06        80\n",
      "         216       0.07      0.10      0.08        80\n",
      "         300       0.07      0.05      0.06        80\n",
      "         301       0.08      0.07      0.08        80\n",
      "         302       0.07      0.12      0.09        80\n",
      "         303       0.08      0.07      0.08        80\n",
      "         304       0.09      0.05      0.06        80\n",
      "         305       0.07      0.07      0.07        80\n",
      "         306       0.08      0.11      0.09        80\n",
      "         307       0.08      0.14      0.10        80\n",
      "         308       0.08      0.12      0.10        80\n",
      "         309       0.08      0.03      0.04        80\n",
      "         310       0.08      0.06      0.07        80\n",
      "         311       0.08      0.07      0.08        80\n",
      "         312       0.08      0.07      0.08        80\n",
      "         313       0.09      0.06      0.07        80\n",
      "         314       0.08      0.05      0.06        80\n",
      "         315       0.08      0.07      0.08        80\n",
      "         400       0.12      0.06      0.08        80\n",
      "         401       0.12      0.10      0.11        80\n",
      "         402       0.14      0.12      0.13        80\n",
      "         403       0.11      0.16      0.13        80\n",
      "         404       0.12      0.10      0.11        80\n",
      "         405       0.13      0.10      0.11        80\n",
      "         406       0.12      0.10      0.11        80\n",
      "         407       0.13      0.16      0.15        80\n",
      "         408       0.12      0.17      0.15        80\n",
      "         409       0.13      0.16      0.15        80\n",
      "         500       0.07      0.16      0.10        80\n",
      "         501       0.06      0.05      0.06        80\n",
      "         502       0.07      0.16      0.10        80\n",
      "         503       0.07      0.07      0.07        80\n",
      "         504       0.06      0.01      0.02        80\n",
      "         505       0.07      0.09      0.08        80\n",
      "         506       0.07      0.05      0.06        80\n",
      "         507       0.07      0.09      0.08        80\n",
      "         508       0.07      0.04      0.05        80\n",
      "         509       0.07      0.06      0.06        80\n",
      "         510       0.07      0.06      0.07        80\n",
      "         511       0.07      0.11      0.09        80\n",
      "         512       0.08      0.04      0.05        80\n",
      "         513       0.07      0.04      0.05        80\n",
      "         514       0.06      0.03      0.04        80\n",
      "         515       0.07      0.04      0.05        80\n",
      "         516       0.07      0.07      0.07        80\n",
      "         517       0.07      0.07      0.07        80\n",
      "         600       0.10      0.09      0.10        80\n",
      "         601       0.11      0.14      0.12        80\n",
      "         602       0.10      0.05      0.07        80\n",
      "         603       0.11      0.29      0.15        80\n",
      "         604       0.11      0.06      0.08        80\n",
      "         605       0.10      0.11      0.11        80\n",
      "         606       0.10      0.03      0.04        80\n",
      "         607       0.10      0.11      0.11        80\n",
      "         608       0.10      0.07      0.09        80\n",
      "         609       0.10      0.14      0.12        80\n",
      "         610       0.10      0.09      0.10        80\n",
      "         611       0.10      0.07      0.09        80\n",
      "         700       0.14      0.26      0.19        80\n",
      "         701       0.13      0.14      0.14        80\n",
      "         702       0.15      0.10      0.12        80\n",
      "         703       0.12      0.06      0.08        80\n",
      "         704       0.14      0.10      0.12        80\n",
      "         705       0.14      0.16      0.15        80\n",
      "         706       0.14      0.19      0.16        80\n",
      "         707       0.14      0.12      0.13        80\n",
      "         708       0.13      0.11      0.12        80\n",
      "         800       0.07      0.04      0.05        80\n",
      "         801       0.08      0.07      0.08        80\n",
      "         802       0.07      0.07      0.07        80\n",
      "         803       0.07      0.06      0.07        80\n",
      "         804       0.06      0.03      0.04        80\n",
      "         805       0.07      0.06      0.07        80\n",
      "         806       0.08      0.06      0.07        80\n",
      "         807       0.07      0.11      0.09        80\n",
      "         808       0.08      0.04      0.05        80\n",
      "         809       0.06      0.09      0.07        80\n",
      "         810       0.07      0.03      0.04        80\n",
      "         811       0.07      0.10      0.08        80\n",
      "         812       0.08      0.09      0.08        80\n",
      "         813       0.07      0.10      0.08        80\n",
      "         814       0.07      0.06      0.06        80\n",
      "         815       0.07      0.09      0.08        80\n",
      "         816       0.07      0.07      0.07        80\n",
      "         817       0.07      0.07      0.07        80\n",
      "         900       0.07      0.04      0.05        80\n",
      "         901       0.07      0.06      0.07        80\n",
      "         902       0.08      0.07      0.08        80\n",
      "         903       0.08      0.06      0.07        80\n",
      "         904       0.07      0.11      0.09        80\n",
      "         905       0.08      0.06      0.07        80\n",
      "         906       0.07      0.06      0.07        80\n",
      "         907       0.07      0.06      0.07        80\n",
      "         908       0.07      0.09      0.08        80\n",
      "         909       0.07      0.03      0.04        80\n",
      "         910       0.08      0.09      0.08        80\n",
      "         911       0.07      0.05      0.06        80\n",
      "         912       0.08      0.09      0.08        80\n",
      "         913       0.07      0.14      0.09        80\n",
      "         914       0.08      0.06      0.07        80\n",
      "         915       0.07      0.09      0.08        80\n",
      "         916       0.07      0.09      0.08        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.09      0.09      0.08     11440\n",
      "weighted avg       0.09      0.09      0.08     11440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make and fit the object\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "# Use it to make predictions\n",
    "train['lm_predicted'] = lm.predict(X_train)\n",
    "# Asssess accuracy\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.lm_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.lm_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.lm_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score(lm, X_train, y_train, cv = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 2.05%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         0   1   2   3   4   5   6   7   8   9  ...  907  908  909  910  \\\n",
      "dt_predicted                                          ...                       \n",
      "3             79  78  79  80  80  78  79  78  78  78  ...   80   80   80   80   \n",
      "409            1   2   1   0   0   2   1   2   2   2  ...    0    0    0    0   \n",
      "601            0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
      "604            0   0   0   0   0   0   0   0   0   0  ...    0    0    0    0   \n",
      "\n",
      "actual        911  912  913  914  915  916  \n",
      "dt_predicted                                \n",
      "3              80   80   80   80   80   80  \n",
      "409             0    0    0    0    0    0  \n",
      "601             0    0    0    0    0    0  \n",
      "604             0    0    0    0    0    0  \n",
      "\n",
      "[4 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00        80\n",
      "           2       0.00      0.00      0.00        80\n",
      "           3       0.01      1.00      0.02        80\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00        80\n",
      "           6       0.00      0.00      0.00        80\n",
      "           7       0.00      0.00      0.00        80\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        80\n",
      "          10       0.00      0.00      0.00        80\n",
      "          11       0.00      0.00      0.00        80\n",
      "          12       0.00      0.00      0.00        80\n",
      "         100       0.00      0.00      0.00        80\n",
      "         101       0.00      0.00      0.00        80\n",
      "         102       0.00      0.00      0.00        80\n",
      "         103       0.00      0.00      0.00        80\n",
      "         104       0.00      0.00      0.00        80\n",
      "         105       0.00      0.00      0.00        80\n",
      "         106       0.00      0.00      0.00        80\n",
      "         107       0.00      0.00      0.00        80\n",
      "         108       0.00      0.00      0.00        80\n",
      "         109       0.00      0.00      0.00        80\n",
      "         110       0.00      0.00      0.00        80\n",
      "         111       0.00      0.00      0.00        80\n",
      "         112       0.00      0.00      0.00        80\n",
      "         200       0.00      0.00      0.00        80\n",
      "         201       0.00      0.00      0.00        80\n",
      "         202       0.00      0.00      0.00        80\n",
      "         203       0.00      0.00      0.00        80\n",
      "         204       0.00      0.00      0.00        80\n",
      "         205       0.00      0.00      0.00        80\n",
      "         206       0.00      0.00      0.00        80\n",
      "         207       0.00      0.00      0.00        80\n",
      "         208       0.00      0.00      0.00        80\n",
      "         209       0.00      0.00      0.00        80\n",
      "         210       0.00      0.00      0.00        80\n",
      "         211       0.00      0.00      0.00        80\n",
      "         212       0.00      0.00      0.00        80\n",
      "         213       0.00      0.00      0.00        80\n",
      "         214       0.00      0.00      0.00        80\n",
      "         215       0.00      0.00      0.00        80\n",
      "         216       0.00      0.00      0.00        80\n",
      "         300       0.00      0.00      0.00        80\n",
      "         301       0.00      0.00      0.00        80\n",
      "         302       0.00      0.00      0.00        80\n",
      "         303       0.00      0.00      0.00        80\n",
      "         304       0.00      0.00      0.00        80\n",
      "         305       0.00      0.00      0.00        80\n",
      "         306       0.00      0.00      0.00        80\n",
      "         307       0.00      0.00      0.00        80\n",
      "         308       0.00      0.00      0.00        80\n",
      "         309       0.00      0.00      0.00        80\n",
      "         310       0.00      0.00      0.00        80\n",
      "         311       0.00      0.00      0.00        80\n",
      "         312       0.00      0.00      0.00        80\n",
      "         313       0.00      0.00      0.00        80\n",
      "         314       0.00      0.00      0.00        80\n",
      "         315       0.00      0.00      0.00        80\n",
      "         400       0.00      0.00      0.00        80\n",
      "         401       0.00      0.00      0.00        80\n",
      "         402       0.00      0.00      0.00        80\n",
      "         403       0.00      0.00      0.00        80\n",
      "         404       0.00      0.00      0.00        80\n",
      "         405       0.00      0.00      0.00        80\n",
      "         406       0.00      0.00      0.00        80\n",
      "         407       0.00      0.00      0.00        80\n",
      "         408       0.00      0.00      0.00        80\n",
      "         409       0.10      0.90      0.18        80\n",
      "         500       0.00      0.00      0.00        80\n",
      "         501       0.00      0.00      0.00        80\n",
      "         502       0.00      0.00      0.00        80\n",
      "         503       0.00      0.00      0.00        80\n",
      "         504       0.00      0.00      0.00        80\n",
      "         505       0.00      0.00      0.00        80\n",
      "         506       0.00      0.00      0.00        80\n",
      "         507       0.00      0.00      0.00        80\n",
      "         508       0.00      0.00      0.00        80\n",
      "         509       0.00      0.00      0.00        80\n",
      "         510       0.00      0.00      0.00        80\n",
      "         511       0.00      0.00      0.00        80\n",
      "         512       0.00      0.00      0.00        80\n",
      "         513       0.00      0.00      0.00        80\n",
      "         514       0.00      0.00      0.00        80\n",
      "         515       0.00      0.00      0.00        80\n",
      "         516       0.00      0.00      0.00        80\n",
      "         517       0.00      0.00      0.00        80\n",
      "         600       0.00      0.00      0.00        80\n",
      "         601       0.12      0.05      0.07        80\n",
      "         602       0.00      0.00      0.00        80\n",
      "         603       0.00      0.00      0.00        80\n",
      "         604       0.09      0.97      0.16        80\n",
      "         605       0.00      0.00      0.00        80\n",
      "         606       0.00      0.00      0.00        80\n",
      "         607       0.00      0.00      0.00        80\n",
      "         608       0.00      0.00      0.00        80\n",
      "         609       0.00      0.00      0.00        80\n",
      "         610       0.00      0.00      0.00        80\n",
      "         611       0.00      0.00      0.00        80\n",
      "         700       0.00      0.00      0.00        80\n",
      "         701       0.00      0.00      0.00        80\n",
      "         702       0.00      0.00      0.00        80\n",
      "         703       0.00      0.00      0.00        80\n",
      "         704       0.00      0.00      0.00        80\n",
      "         705       0.00      0.00      0.00        80\n",
      "         706       0.00      0.00      0.00        80\n",
      "         707       0.00      0.00      0.00        80\n",
      "         708       0.00      0.00      0.00        80\n",
      "         800       0.00      0.00      0.00        80\n",
      "         801       0.00      0.00      0.00        80\n",
      "         802       0.00      0.00      0.00        80\n",
      "         803       0.00      0.00      0.00        80\n",
      "         804       0.00      0.00      0.00        80\n",
      "         805       0.00      0.00      0.00        80\n",
      "         806       0.00      0.00      0.00        80\n",
      "         807       0.00      0.00      0.00        80\n",
      "         808       0.00      0.00      0.00        80\n",
      "         809       0.00      0.00      0.00        80\n",
      "         810       0.00      0.00      0.00        80\n",
      "         811       0.00      0.00      0.00        80\n",
      "         812       0.00      0.00      0.00        80\n",
      "         813       0.00      0.00      0.00        80\n",
      "         814       0.00      0.00      0.00        80\n",
      "         815       0.00      0.00      0.00        80\n",
      "         816       0.00      0.00      0.00        80\n",
      "         817       0.00      0.00      0.00        80\n",
      "         900       0.00      0.00      0.00        80\n",
      "         901       0.00      0.00      0.00        80\n",
      "         902       0.00      0.00      0.00        80\n",
      "         903       0.00      0.00      0.00        80\n",
      "         904       0.00      0.00      0.00        80\n",
      "         905       0.00      0.00      0.00        80\n",
      "         906       0.00      0.00      0.00        80\n",
      "         907       0.00      0.00      0.00        80\n",
      "         908       0.00      0.00      0.00        80\n",
      "         909       0.00      0.00      0.00        80\n",
      "         910       0.00      0.00      0.00        80\n",
      "         911       0.00      0.00      0.00        80\n",
      "         912       0.00      0.00      0.00        80\n",
      "         913       0.00      0.00      0.00        80\n",
      "         914       0.00      0.00      0.00        80\n",
      "         915       0.00      0.00      0.00        80\n",
      "         916       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.02     11440\n",
      "   macro avg       0.00      0.02      0.00     11440\n",
      "weighted avg       0.00      0.02      0.00     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make and fit the object\n",
    "dtc = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train)\n",
    "# Use the object\n",
    "train['dt_predicted'] = dtc.predict(X_train)\n",
    "# Determine performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.dt_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.dt_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.dt_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        0   1   2  3   4  5  6   7   8   9  ...  907  908  909  910  \\\n",
      "rf_predicted                                      ...                       \n",
      "0             6   6   2  5   4  5  4   4   5   5  ...    0    0    0    0   \n",
      "1             2   6   5  6   5  2  6   5   5   4  ...    0    0    0    0   \n",
      "2             7   6   7  7   5  5  6   6   6   4  ...    0    0    0    0   \n",
      "3             4   4   5  6   5  6  5   6   5   5  ...    0    0    0    0   \n",
      "4             9  12  12  8  13  9  9  11  10  11  ...    0    0    0    0   \n",
      "...          ..  ..  .. ..  .. .. ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
      "912           0   0   0  0   0  0  0   0   0   0  ...    3    3    5    5   \n",
      "913           0   0   0  0   0  0  0   0   0   0  ...    5    5    4    6   \n",
      "914           0   0   0  0   0  0  0   0   0   0  ...    3    3    4    1   \n",
      "915           0   0   0  0   0  0  0   0   0   0  ...    3    2    2    2   \n",
      "916           0   0   0  0   0  0  0   0   0   0  ...    4    5    4    4   \n",
      "\n",
      "actual        911  912  913  914  915  916  \n",
      "rf_predicted                                \n",
      "0               0    0    0    0    0    0  \n",
      "1               0    0    0    0    0    0  \n",
      "2               0    0    0    0    0    0  \n",
      "3               0    0    0    0    0    0  \n",
      "4               0    0    0    0    0    0  \n",
      "...           ...  ...  ...  ...  ...  ...  \n",
      "912             4    5    5    5    1    3  \n",
      "913             3    4    6    5    6    6  \n",
      "914             3    2    2    4    3    4  \n",
      "915             2    3    3    2    3    2  \n",
      "916             4    3    3    4    5    5  \n",
      "\n",
      "[142 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.07      0.09        80\n",
      "           1       0.10      0.07      0.09        80\n",
      "           2       0.09      0.09      0.09        80\n",
      "           3       0.09      0.07      0.08        80\n",
      "           4       0.09      0.16      0.12        80\n",
      "           5       0.10      0.17      0.12        80\n",
      "           6       0.10      0.07      0.08        80\n",
      "           7       0.09      0.09      0.09        80\n",
      "           8       0.10      0.06      0.08        80\n",
      "           9       0.10      0.12      0.11        80\n",
      "          10       0.09      0.06      0.08        80\n",
      "          11       0.10      0.07      0.09        80\n",
      "          12       0.09      0.11      0.10        80\n",
      "         100       0.10      0.06      0.08        80\n",
      "         101       0.10      0.15      0.12        80\n",
      "         102       0.09      0.09      0.09        80\n",
      "         103       0.10      0.07      0.09        80\n",
      "         104       0.10      0.10      0.10        80\n",
      "         105       0.10      0.05      0.07        80\n",
      "         106       0.10      0.07      0.08        80\n",
      "         107       0.10      0.21      0.13        80\n",
      "         108       0.09      0.11      0.10        80\n",
      "         109       0.10      0.14      0.12        80\n",
      "         110       0.09      0.03      0.04        80\n",
      "         111       0.09      0.10      0.10        80\n",
      "         112       0.09      0.06      0.08        80\n",
      "         200       0.07      0.10      0.09        80\n",
      "         201       0.08      0.06      0.07        80\n",
      "         202       0.07      0.14      0.09        80\n",
      "         203       0.07      0.09      0.08        80\n",
      "         204       0.06      0.03      0.04        80\n",
      "         205       0.07      0.07      0.07        80\n",
      "         206       0.08      0.10      0.09        80\n",
      "         207       0.08      0.04      0.05        80\n",
      "         208       0.08      0.03      0.04        80\n",
      "         209       0.08      0.06      0.07        80\n",
      "         210       0.07      0.14      0.09        80\n",
      "         211       0.08      0.04      0.05        80\n",
      "         212       0.07      0.05      0.06        80\n",
      "         213       0.07      0.01      0.02        80\n",
      "         214       0.06      0.01      0.02        80\n",
      "         215       0.08      0.17      0.11        80\n",
      "         216       0.07      0.11      0.09        80\n",
      "         300       0.08      0.11      0.10        80\n",
      "         301       0.07      0.10      0.09        80\n",
      "         302       0.07      0.15      0.10        80\n",
      "         303       0.08      0.05      0.06        80\n",
      "         304       0.08      0.14      0.10        80\n",
      "         305       0.08      0.05      0.06        80\n",
      "         306       0.08      0.11      0.09        80\n",
      "         307       0.07      0.10      0.09        80\n",
      "         308       0.08      0.14      0.10        80\n",
      "         309       0.08      0.10      0.09        80\n",
      "         310       0.08      0.04      0.05        80\n",
      "         311       0.08      0.04      0.05        80\n",
      "         312       0.10      0.01      0.02        80\n",
      "         313       0.08      0.09      0.08        80\n",
      "         314       0.08      0.03      0.04        80\n",
      "         315       0.00      0.00      0.00        80\n",
      "         400       0.13      0.09      0.10        80\n",
      "         401       0.12      0.14      0.13        80\n",
      "         402       0.12      0.15      0.13        80\n",
      "         403       0.13      0.07      0.09        80\n",
      "         404       0.13      0.24      0.17        80\n",
      "         405       0.14      0.06      0.09        80\n",
      "         406       0.13      0.09      0.10        80\n",
      "         407       0.12      0.17      0.15        80\n",
      "         408       0.13      0.09      0.11        80\n",
      "         409       0.12      0.15      0.13        80\n",
      "         500       0.07      0.05      0.06        80\n",
      "         501       0.07      0.12      0.09        80\n",
      "         502       0.08      0.09      0.08        80\n",
      "         503       0.07      0.06      0.07        80\n",
      "         504       0.07      0.07      0.07        80\n",
      "         505       0.07      0.03      0.04        80\n",
      "         506       0.07      0.12      0.09        80\n",
      "         507       0.07      0.06      0.07        80\n",
      "         508       0.08      0.04      0.05        80\n",
      "         509       0.06      0.05      0.06        80\n",
      "         510       0.07      0.05      0.06        80\n",
      "         511       0.06      0.09      0.07        80\n",
      "         512       0.07      0.06      0.06        80\n",
      "         513       0.07      0.07      0.07        80\n",
      "         514       0.07      0.04      0.05        80\n",
      "         515       0.08      0.01      0.02        80\n",
      "         516       0.07      0.11      0.09        80\n",
      "         517       0.07      0.11      0.09        80\n",
      "         600       0.10      0.09      0.09        80\n",
      "         601       0.10      0.09      0.09        80\n",
      "         602       0.10      0.14      0.12        80\n",
      "         603       0.12      0.05      0.07        80\n",
      "         604       0.11      0.12      0.11        80\n",
      "         605       0.10      0.23      0.14        80\n",
      "         606       0.10      0.10      0.10        80\n",
      "         607       0.11      0.05      0.07        80\n",
      "         608       0.10      0.05      0.07        80\n",
      "         609       0.11      0.15      0.13        80\n",
      "         610       0.10      0.11      0.11        80\n",
      "         611       0.10      0.07      0.09        80\n",
      "         700       0.16      0.10      0.12        80\n",
      "         701       0.15      0.06      0.09        80\n",
      "         702       0.14      0.12      0.13        80\n",
      "         703       0.13      0.12      0.13        80\n",
      "         704       0.14      0.21      0.17        80\n",
      "         705       0.13      0.33      0.19        80\n",
      "         706       0.14      0.07      0.10        80\n",
      "         707       0.15      0.10      0.12        80\n",
      "         708       0.14      0.12      0.13        80\n",
      "         800       0.07      0.12      0.09        80\n",
      "         801       0.07      0.03      0.04        80\n",
      "         802       0.07      0.10      0.08        80\n",
      "         803       0.07      0.09      0.08        80\n",
      "         804       0.06      0.05      0.06        80\n",
      "         805       0.06      0.03      0.04        80\n",
      "         806       0.07      0.10      0.08        80\n",
      "         807       0.07      0.12      0.09        80\n",
      "         808       0.07      0.11      0.09        80\n",
      "         809       0.06      0.07      0.07        80\n",
      "         810       0.07      0.05      0.06        80\n",
      "         811       0.07      0.03      0.04        80\n",
      "         812       0.07      0.03      0.04        80\n",
      "         813       0.07      0.06      0.06        80\n",
      "         814       0.07      0.11      0.08        80\n",
      "         815       0.07      0.05      0.06        80\n",
      "         816       0.07      0.05      0.06        80\n",
      "         817       0.08      0.05      0.06        80\n",
      "         900       0.07      0.09      0.08        80\n",
      "         901       0.07      0.06      0.07        80\n",
      "         902       0.07      0.11      0.09        80\n",
      "         903       0.08      0.07      0.08        80\n",
      "         904       0.07      0.09      0.08        80\n",
      "         905       0.07      0.06      0.07        80\n",
      "         906       0.08      0.06      0.07        80\n",
      "         907       0.07      0.06      0.07        80\n",
      "         908       0.07      0.09      0.08        80\n",
      "         909       0.07      0.07      0.07        80\n",
      "         910       0.08      0.10      0.09        80\n",
      "         911       0.08      0.09      0.08        80\n",
      "         912       0.07      0.06      0.07        80\n",
      "         913       0.07      0.07      0.07        80\n",
      "         914       0.08      0.05      0.06        80\n",
      "         915       0.07      0.04      0.05        80\n",
      "         916       0.07      0.06      0.07        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.09      0.09      0.08     11440\n",
      "weighted avg       0.09      0.09      0.08     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make and fit object\n",
    "rf = RandomForestClassifier(bootstrap = True, \n",
    "                            class_weight = None, \n",
    "                            criterion = 'gini',\n",
    "                            min_samples_leaf = 3,\n",
    "                            n_estimators = 100,\n",
    "                            max_depth = 8, \n",
    "                            random_state = 123).fit(X_train, y_train)\n",
    "# Use it to make predictions\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "# Assess performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          0   1   2   3   4   5   6   7   8   9  ...  907  908  909  \\\n",
      "knn_predicted                                          ...                  \n",
      "0              34  28  24  27  27  26  26  25  27  27  ...    0    0    0   \n",
      "1              19  27  27  21  20  20  20  24  22  21  ...    0    0    0   \n",
      "2              11  10  14   9  11  13  12  12  11  12  ...    0    0    0   \n",
      "3               5   5   5   9   7   7   9   6   8   6  ...    0    0    0   \n",
      "4               4   3   5   6   6   5   6   5   3   4  ...    0    0    0   \n",
      "...            ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...   \n",
      "904             0   0   0   0   0   0   0   0   0   0  ...    4    5    6   \n",
      "905             0   0   0   0   0   0   0   0   0   0  ...    3    3    4   \n",
      "906             0   0   0   0   0   0   0   0   0   0  ...    9   10   10   \n",
      "907             0   0   0   0   0   0   0   0   0   0  ...    5    5    5   \n",
      "908             0   0   0   0   0   0   0   0   0   0  ...    3    4    4   \n",
      "\n",
      "actual         910  911  912  913  914  915  916  \n",
      "knn_predicted                                     \n",
      "0                0    0    0    0    0    0    0  \n",
      "1                0    0    0    0    0    0    0  \n",
      "2                0    0    0    0    0    0    0  \n",
      "3                0    0    0    0    0    0    0  \n",
      "4                0    0    0    0    0    0    0  \n",
      "...            ...  ...  ...  ...  ...  ...  ...  \n",
      "904              4    3    5    6    5    6    5  \n",
      "905              5    4    4    3    2    4    4  \n",
      "906              8    9    7    8    6    8    7  \n",
      "907              5    4    4    4    3    5    5  \n",
      "908              3    3    4    4    4    3    3  \n",
      "\n",
      "[90 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.42      0.16        80\n",
      "           1       0.10      0.34      0.15        80\n",
      "           2       0.09      0.17      0.12        80\n",
      "           3       0.10      0.11      0.11        80\n",
      "           4       0.10      0.07      0.08        80\n",
      "           5       0.10      0.05      0.07        80\n",
      "           6       0.10      0.03      0.04        80\n",
      "           7       0.08      0.01      0.02        80\n",
      "           8       0.10      0.04      0.05        80\n",
      "           9       0.00      0.00      0.00        80\n",
      "          10       0.00      0.00      0.00        80\n",
      "          11       0.00      0.00      0.00        80\n",
      "          12       0.00      0.00      0.00        80\n",
      "         100       0.10      0.39      0.16        80\n",
      "         101       0.10      0.28      0.14        80\n",
      "         102       0.09      0.19      0.13        80\n",
      "         103       0.10      0.14      0.11        80\n",
      "         104       0.09      0.11      0.10        80\n",
      "         105       0.10      0.11      0.11        80\n",
      "         106       0.08      0.03      0.04        80\n",
      "         107       0.00      0.00      0.00        80\n",
      "         108       0.08      0.01      0.02        80\n",
      "         109       0.00      0.00      0.00        80\n",
      "         110       0.00      0.00      0.00        80\n",
      "         111       0.00      0.00      0.00        80\n",
      "         112       0.00      0.00      0.00        80\n",
      "         200       0.07      0.23      0.11        80\n",
      "         201       0.07      0.20      0.10        80\n",
      "         202       0.07      0.24      0.11        80\n",
      "         203       0.08      0.15      0.10        80\n",
      "         204       0.08      0.14      0.10        80\n",
      "         205       0.08      0.09      0.08        80\n",
      "         206       0.07      0.06      0.07        80\n",
      "         207       0.07      0.04      0.05        80\n",
      "         208       0.07      0.07      0.07        80\n",
      "         209       0.07      0.03      0.04        80\n",
      "         210       0.09      0.01      0.02        80\n",
      "         211       0.00      0.00      0.00        80\n",
      "         212       0.00      0.00      0.00        80\n",
      "         213       0.00      0.00      0.00        80\n",
      "         214       0.00      0.00      0.00        80\n",
      "         215       0.00      0.00      0.00        80\n",
      "         216       0.00      0.00      0.00        80\n",
      "         300       0.08      0.30      0.12        80\n",
      "         301       0.08      0.17      0.11        80\n",
      "         302       0.08      0.15      0.10        80\n",
      "         303       0.08      0.23      0.12        80\n",
      "         304       0.08      0.16      0.11        80\n",
      "         305       0.08      0.10      0.09        80\n",
      "         306       0.08      0.05      0.06        80\n",
      "         307       0.08      0.03      0.04        80\n",
      "         308       0.09      0.03      0.04        80\n",
      "         309       0.07      0.03      0.04        80\n",
      "         310       0.00      0.00      0.00        80\n",
      "         311       0.07      0.01      0.02        80\n",
      "         312       0.00      0.00      0.00        80\n",
      "         313       0.00      0.00      0.00        80\n",
      "         314       0.00      0.00      0.00        80\n",
      "         315       0.00      0.00      0.00        80\n",
      "         400       0.13      0.41      0.20        80\n",
      "         401       0.12      0.31      0.18        80\n",
      "         402       0.12      0.23      0.16        80\n",
      "         403       0.13      0.16      0.14        80\n",
      "         404       0.12      0.07      0.09        80\n",
      "         405       0.11      0.06      0.08        80\n",
      "         406       0.00      0.00      0.00        80\n",
      "         407       0.00      0.00      0.00        80\n",
      "         408       0.00      0.00      0.00        80\n",
      "         409       0.00      0.00      0.00        80\n",
      "         500       0.07      0.29      0.11        80\n",
      "         501       0.07      0.24      0.11        80\n",
      "         502       0.07      0.14      0.09        80\n",
      "         503       0.07      0.11      0.09        80\n",
      "         504       0.07      0.10      0.08        80\n",
      "         505       0.07      0.11      0.08        80\n",
      "         506       0.07      0.09      0.08        80\n",
      "         507       0.07      0.04      0.05        80\n",
      "         508       0.06      0.04      0.05        80\n",
      "         509       0.06      0.01      0.02        80\n",
      "         510       0.07      0.05      0.06        80\n",
      "         511       0.07      0.04      0.05        80\n",
      "         512       0.00      0.00      0.00        80\n",
      "         513       0.00      0.00      0.00        80\n",
      "         514       0.00      0.00      0.00        80\n",
      "         515       0.00      0.00      0.00        80\n",
      "         516       0.00      0.00      0.00        80\n",
      "         517       0.00      0.00      0.00        80\n",
      "         600       0.10      0.49      0.17        80\n",
      "         601       0.10      0.30      0.16        80\n",
      "         602       0.11      0.17      0.13        80\n",
      "         603       0.11      0.12      0.12        80\n",
      "         604       0.11      0.12      0.11        80\n",
      "         605       0.10      0.01      0.02        80\n",
      "         606       0.11      0.03      0.04        80\n",
      "         607       0.00      0.00      0.00        80\n",
      "         608       0.00      0.00      0.00        80\n",
      "         609       0.00      0.00      0.00        80\n",
      "         610       0.00      0.00      0.00        80\n",
      "         611       0.00      0.00      0.00        80\n",
      "         700       0.14      0.60      0.23        80\n",
      "         701       0.14      0.33      0.19        80\n",
      "         702       0.14      0.19      0.16        80\n",
      "         703       0.13      0.09      0.11        80\n",
      "         704       0.13      0.05      0.07        80\n",
      "         705       0.00      0.00      0.00        80\n",
      "         706       0.00      0.00      0.00        80\n",
      "         707       0.00      0.00      0.00        80\n",
      "         708       0.00      0.00      0.00        80\n",
      "         800       0.07      0.23      0.11        80\n",
      "         801       0.07      0.20      0.10        80\n",
      "         802       0.07      0.21      0.10        80\n",
      "         803       0.07      0.16      0.10        80\n",
      "         804       0.07      0.09      0.08        80\n",
      "         805       0.07      0.12      0.09        80\n",
      "         806       0.08      0.06      0.07        80\n",
      "         807       0.07      0.04      0.05        80\n",
      "         808       0.07      0.05      0.06        80\n",
      "         809       0.06      0.06      0.06        80\n",
      "         810       0.07      0.01      0.02        80\n",
      "         811       0.07      0.01      0.02        80\n",
      "         812       0.00      0.00      0.00        80\n",
      "         813       0.00      0.00      0.00        80\n",
      "         814       0.00      0.00      0.00        80\n",
      "         815       0.00      0.00      0.00        80\n",
      "         816       0.00      0.00      0.00        80\n",
      "         817       0.00      0.00      0.00        80\n",
      "         900       0.07      0.28      0.12        80\n",
      "         901       0.07      0.26      0.11        80\n",
      "         902       0.07      0.23      0.11        80\n",
      "         903       0.08      0.10      0.09        80\n",
      "         904       0.08      0.09      0.08        80\n",
      "         905       0.08      0.06      0.07        80\n",
      "         906       0.07      0.12      0.09        80\n",
      "         907       0.07      0.06      0.07        80\n",
      "         908       0.07      0.05      0.06        80\n",
      "         909       0.00      0.00      0.00        80\n",
      "         910       0.00      0.00      0.00        80\n",
      "         911       0.00      0.00      0.00        80\n",
      "         912       0.00      0.00      0.00        80\n",
      "         913       0.00      0.00      0.00        80\n",
      "         914       0.00      0.00      0.00        80\n",
      "         915       0.00      0.00      0.00        80\n",
      "         916       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.05      0.09      0.06     11440\n",
      "weighted avg       0.05      0.09      0.06     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Make and fit the object\n",
    "knn = KNeighborsClassifier(n_neighbors = 4).fit(X_train, y_train)\n",
    "# Use the object \n",
    "train['knn_predicted'] = knn.predict(X_train)\n",
    "# Evaluate performance\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.knn_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          0  1   2  3   4   5   6  7   8   9  ...  907  908  909  910  \\\n",
      "svc_predicted                                       ...                       \n",
      "0              10  7   9  8   7   8   9  8  10   7  ...    0    0    0    0   \n",
      "1               5  7   4  6   5   7   7  7   5   6  ...    0    0    0    0   \n",
      "2               5  4   7  6   6   6   6  5   4   4  ...    0    0    0    0   \n",
      "3               7  4   4  8   7   7   7  5   5   7  ...    0    0    0    0   \n",
      "4               8  8  10  8  12  10  12  9  11  11  ...    0    0    0    0   \n",
      "...            .. ..  .. ..  ..  ..  .. ..  ..  ..  ...  ...  ...  ...  ...   \n",
      "912             0  0   0  0   0   0   0  0   0   0  ...    5    6    6    5   \n",
      "913             0  0   0  0   0   0   0  0   0   0  ...    7    7    9    9   \n",
      "914             0  0   0  0   0   0   0  0   0   0  ...    4    5    4    5   \n",
      "915             0  0   0  0   0   0   0  0   0   0  ...    5    6    5    5   \n",
      "916             0  0   0  0   0   0   0  0   0   0  ...    4    5    4    3   \n",
      "\n",
      "actual         911  912  913  914  915  916  \n",
      "svc_predicted                                \n",
      "0                0    0    0    0    0    0  \n",
      "1                0    0    0    0    0    0  \n",
      "2                0    0    0    0    0    0  \n",
      "3                0    0    0    0    0    0  \n",
      "4                0    0    0    0    0    0  \n",
      "...            ...  ...  ...  ...  ...  ...  \n",
      "912              5    6    3    4    4    4  \n",
      "913              8    7   10    7    6    7  \n",
      "914              6    6    5    7    6    5  \n",
      "915              5    5    4    4    6    5  \n",
      "916              3    4    2    4    4    5  \n",
      "\n",
      "[143 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.12      0.11        80\n",
      "           1       0.09      0.09      0.09        80\n",
      "           2       0.10      0.09      0.09        80\n",
      "           3       0.10      0.10      0.10        80\n",
      "           4       0.09      0.15      0.12        80\n",
      "           5       0.09      0.06      0.08        80\n",
      "           6       0.09      0.11      0.10        80\n",
      "           7       0.10      0.07      0.09        80\n",
      "           8       0.10      0.05      0.07        80\n",
      "           9       0.10      0.11      0.10        80\n",
      "          10       0.09      0.09      0.09        80\n",
      "          11       0.10      0.16      0.12        80\n",
      "          12       0.09      0.04      0.05        80\n",
      "         100       0.10      0.15      0.12        80\n",
      "         101       0.10      0.16      0.12        80\n",
      "         102       0.10      0.05      0.07        80\n",
      "         103       0.11      0.04      0.06        80\n",
      "         104       0.10      0.03      0.04        80\n",
      "         105       0.09      0.10      0.10        80\n",
      "         106       0.10      0.07      0.08        80\n",
      "         107       0.09      0.10      0.09        80\n",
      "         108       0.10      0.09      0.09        80\n",
      "         109       0.10      0.09      0.09        80\n",
      "         110       0.10      0.11      0.10        80\n",
      "         111       0.09      0.12      0.11        80\n",
      "         112       0.10      0.14      0.11        80\n",
      "         200       0.07      0.06      0.06        80\n",
      "         201       0.07      0.04      0.05        80\n",
      "         202       0.07      0.06      0.07        80\n",
      "         203       0.07      0.05      0.06        80\n",
      "         204       0.08      0.03      0.04        80\n",
      "         205       0.08      0.05      0.06        80\n",
      "         206       0.07      0.10      0.08        80\n",
      "         207       0.07      0.06      0.07        80\n",
      "         208       0.07      0.07      0.07        80\n",
      "         209       0.08      0.10      0.09        80\n",
      "         210       0.08      0.07      0.08        80\n",
      "         211       0.08      0.12      0.09        80\n",
      "         212       0.07      0.11      0.09        80\n",
      "         213       0.07      0.07      0.07        80\n",
      "         214       0.07      0.09      0.08        80\n",
      "         215       0.07      0.07      0.07        80\n",
      "         216       0.07      0.07      0.07        80\n",
      "         300       0.07      0.06      0.07        80\n",
      "         301       0.08      0.09      0.08        80\n",
      "         302       0.08      0.14      0.10        80\n",
      "         303       0.08      0.05      0.06        80\n",
      "         304       0.08      0.05      0.06        80\n",
      "         305       0.08      0.11      0.09        80\n",
      "         306       0.08      0.15      0.11        80\n",
      "         307       0.07      0.10      0.09        80\n",
      "         308       0.08      0.11      0.09        80\n",
      "         309       0.08      0.04      0.05        80\n",
      "         310       0.08      0.09      0.08        80\n",
      "         311       0.08      0.04      0.05        80\n",
      "         312       0.07      0.06      0.07        80\n",
      "         313       0.08      0.04      0.05        80\n",
      "         314       0.08      0.05      0.06        80\n",
      "         315       0.08      0.07      0.08        80\n",
      "         400       0.12      0.12      0.12        80\n",
      "         401       0.13      0.09      0.10        80\n",
      "         402       0.14      0.07      0.10        80\n",
      "         403       0.11      0.14      0.12        80\n",
      "         404       0.14      0.06      0.09        80\n",
      "         405       0.14      0.10      0.12        80\n",
      "         406       0.12      0.16      0.14        80\n",
      "         407       0.13      0.16      0.14        80\n",
      "         408       0.12      0.17      0.14        80\n",
      "         409       0.13      0.16      0.14        80\n",
      "         500       0.07      0.11      0.08        80\n",
      "         501       0.07      0.07      0.07        80\n",
      "         502       0.07      0.10      0.08        80\n",
      "         503       0.07      0.06      0.07        80\n",
      "         504       0.07      0.03      0.04        80\n",
      "         505       0.07      0.09      0.08        80\n",
      "         506       0.07      0.06      0.07        80\n",
      "         507       0.07      0.09      0.08        80\n",
      "         508       0.06      0.07      0.07        80\n",
      "         509       0.07      0.05      0.06        80\n",
      "         510       0.07      0.07      0.07        80\n",
      "         511       0.08      0.09      0.08        80\n",
      "         512       0.08      0.04      0.05        80\n",
      "         513       0.07      0.04      0.05        80\n",
      "         514       0.07      0.05      0.06        80\n",
      "         515       0.07      0.07      0.07        80\n",
      "         516       0.07      0.07      0.07        80\n",
      "         517       0.07      0.07      0.07        80\n",
      "         600       0.10      0.10      0.10        80\n",
      "         601       0.11      0.11      0.11        80\n",
      "         602       0.10      0.07      0.08        80\n",
      "         603       0.11      0.21      0.14        80\n",
      "         604       0.11      0.09      0.10        80\n",
      "         605       0.10      0.11      0.11        80\n",
      "         606       0.10      0.04      0.06        80\n",
      "         607       0.10      0.10      0.10        80\n",
      "         608       0.11      0.10      0.10        80\n",
      "         609       0.11      0.14      0.12        80\n",
      "         610       0.10      0.11      0.11        80\n",
      "         611       0.10      0.06      0.08        80\n",
      "         700       0.15      0.20      0.17        80\n",
      "         701       0.13      0.17      0.15        80\n",
      "         702       0.14      0.19      0.16        80\n",
      "         703       0.14      0.07      0.10        80\n",
      "         704       0.14      0.10      0.12        80\n",
      "         705       0.14      0.14      0.14        80\n",
      "         706       0.13      0.14      0.14        80\n",
      "         707       0.14      0.16      0.15        80\n",
      "         708       0.14      0.07      0.10        80\n",
      "         800       0.07      0.06      0.06        80\n",
      "         801       0.08      0.06      0.07        80\n",
      "         802       0.07      0.09      0.08        80\n",
      "         803       0.07      0.09      0.08        80\n",
      "         804       0.07      0.05      0.06        80\n",
      "         805       0.07      0.04      0.05        80\n",
      "         806       0.08      0.06      0.07        80\n",
      "         807       0.07      0.10      0.08        80\n",
      "         808       0.08      0.06      0.07        80\n",
      "         809       0.06      0.07      0.07        80\n",
      "         810       0.06      0.05      0.06        80\n",
      "         811       0.06      0.09      0.07        80\n",
      "         812       0.07      0.09      0.08        80\n",
      "         813       0.07      0.10      0.08        80\n",
      "         814       0.07      0.05      0.06        80\n",
      "         815       0.07      0.07      0.07        80\n",
      "         816       0.07      0.05      0.06        80\n",
      "         817       0.07      0.06      0.07        80\n",
      "         900       0.07      0.06      0.07        80\n",
      "         901       0.07      0.11      0.09        80\n",
      "         902       0.08      0.06      0.07        80\n",
      "         903       0.08      0.04      0.05        80\n",
      "         904       0.07      0.07      0.07        80\n",
      "         905       0.07      0.06      0.07        80\n",
      "         906       0.07      0.10      0.08        80\n",
      "         907       0.07      0.06      0.07        80\n",
      "         908       0.07      0.07      0.07        80\n",
      "         909       0.06      0.03      0.04        80\n",
      "         910       0.08      0.07      0.08        80\n",
      "         911       0.07      0.07      0.07        80\n",
      "         912       0.07      0.07      0.07        80\n",
      "         913       0.07      0.12      0.09        80\n",
      "         914       0.08      0.09      0.08        80\n",
      "         915       0.07      0.07      0.07        80\n",
      "         916       0.08      0.06      0.07        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.09      0.09      0.08     11440\n",
      "weighted avg       0.09      0.09      0.08     11440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make and fit the object\n",
    "svc = LinearSVC(random_state=0).fit(X_train, y_train)\n",
    "# Use the object\n",
    "train['svc_predicted'] = svc.predict(X_train)\n",
    "# Evaluate model\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.svc_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.svc_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.svc_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          0   1   2   3   4   5   6   7   8   9  ...  907  908  909  \\\n",
      "gnb_predicted                                          ...                  \n",
      "6              11  13  12  15  14  11  16  10  15  14  ...    0    0    0   \n",
      "7               1   1   0   1   1   1   0   1   1   1  ...    0    0    0   \n",
      "10              2   3   3   2   2   3   0   2   3   3  ...    0    0    0   \n",
      "11             66  63  65  62  63  65  64  67  61  62  ...    0    0    0   \n",
      "101             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "105             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "111             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "112             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "204             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "205             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "213             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "302             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "303             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "304             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "310             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "401             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "403             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "405             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "406             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "407             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "504             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "506             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "511             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "512             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "600             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "603             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "604             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "609             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "700             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "703             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "705             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "706             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "708             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "805             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "806             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "809             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "815             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "816             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "902             0   0   0   0   0   0   0   0   0   0  ...    1    1    0   \n",
      "904             0   0   0   0   0   0   0   0   0   0  ...   15   14   12   \n",
      "913             0   0   0   0   0   0   0   0   0   0  ...   61   62   64   \n",
      "915             0   0   0   0   0   0   0   0   0   0  ...    3    3    4   \n",
      "\n",
      "actual         910  911  912  913  914  915  916  \n",
      "gnb_predicted                                     \n",
      "6                0    0    0    0    0    0    0  \n",
      "7                0    0    0    0    0    0    0  \n",
      "10               0    0    0    0    0    0    0  \n",
      "11               0    0    0    0    0    0    0  \n",
      "101              0    0    0    0    0    0    0  \n",
      "105              0    0    0    0    0    0    0  \n",
      "111              0    0    0    0    0    0    0  \n",
      "112              0    0    0    0    0    0    0  \n",
      "204              0    0    0    0    0    0    0  \n",
      "205              0    0    0    0    0    0    0  \n",
      "213              0    0    0    0    0    0    0  \n",
      "302              0    0    0    0    0    0    0  \n",
      "303              0    0    0    0    0    0    0  \n",
      "304              0    0    0    0    0    0    0  \n",
      "310              0    0    0    0    0    0    0  \n",
      "401              0    0    0    0    0    0    0  \n",
      "403              0    0    0    0    0    0    0  \n",
      "405              0    0    0    0    0    0    0  \n",
      "406              0    0    0    0    0    0    0  \n",
      "407              0    0    0    0    0    0    0  \n",
      "504              0    0    0    0    0    0    0  \n",
      "506              0    0    0    0    0    0    0  \n",
      "511              0    0    0    0    0    0    0  \n",
      "512              0    0    0    0    0    0    0  \n",
      "600              0    0    0    0    0    0    0  \n",
      "603              0    0    0    0    0    0    0  \n",
      "604              0    0    0    0    0    0    0  \n",
      "609              0    0    0    0    0    0    0  \n",
      "700              0    0    0    0    0    0    0  \n",
      "703              0    0    0    0    0    0    0  \n",
      "705              0    0    0    0    0    0    0  \n",
      "706              0    0    0    0    0    0    0  \n",
      "708              0    0    0    0    0    0    0  \n",
      "805              0    0    0    0    0    0    0  \n",
      "806              0    0    0    0    0    0    0  \n",
      "809              0    0    0    0    0    0    0  \n",
      "815              0    0    0    0    0    0    0  \n",
      "816              0    0    0    0    0    0    0  \n",
      "902              0    1    1    0    1    0    1  \n",
      "904             14   14   12    2   14   13   14  \n",
      "913             64   61   64   78   62   63   62  \n",
      "915              2    4    3    0    3    4    3  \n",
      "\n",
      "[42 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        80\n",
      "           1       0.00      0.00      0.00        80\n",
      "           2       0.00      0.00      0.00        80\n",
      "           3       0.00      0.00      0.00        80\n",
      "           4       0.00      0.00      0.00        80\n",
      "           5       0.00      0.00      0.00        80\n",
      "           6       0.10      0.20      0.14        80\n",
      "           7       0.10      0.01      0.02        80\n",
      "           8       0.00      0.00      0.00        80\n",
      "           9       0.00      0.00      0.00        80\n",
      "          10       0.10      0.04      0.06        80\n",
      "          11       0.09      1.00      0.17        80\n",
      "          12       0.00      0.00      0.00        80\n",
      "         100       0.00      0.00      0.00        80\n",
      "         101       0.10      0.09      0.09        80\n",
      "         102       0.00      0.00      0.00        80\n",
      "         103       0.00      0.00      0.00        80\n",
      "         104       0.00      0.00      0.00        80\n",
      "         105       0.09      1.00      0.17        80\n",
      "         106       0.00      0.00      0.00        80\n",
      "         107       0.00      0.00      0.00        80\n",
      "         108       0.00      0.00      0.00        80\n",
      "         109       0.00      0.00      0.00        80\n",
      "         110       0.00      0.00      0.00        80\n",
      "         111       0.09      0.01      0.02        80\n",
      "         112       0.11      0.15      0.12        80\n",
      "         200       0.00      0.00      0.00        80\n",
      "         201       0.00      0.00      0.00        80\n",
      "         202       0.00      0.00      0.00        80\n",
      "         203       0.00      0.00      0.00        80\n",
      "         204       0.07      0.96      0.13        80\n",
      "         205       0.09      0.04      0.05        80\n",
      "         206       0.00      0.00      0.00        80\n",
      "         207       0.00      0.00      0.00        80\n",
      "         208       0.00      0.00      0.00        80\n",
      "         209       0.00      0.00      0.00        80\n",
      "         210       0.00      0.00      0.00        80\n",
      "         211       0.00      0.00      0.00        80\n",
      "         212       0.00      0.00      0.00        80\n",
      "         213       0.08      0.25      0.12        80\n",
      "         214       0.00      0.00      0.00        80\n",
      "         215       0.00      0.00      0.00        80\n",
      "         216       0.00      0.00      0.00        80\n",
      "         300       0.00      0.00      0.00        80\n",
      "         301       0.00      0.00      0.00        80\n",
      "         302       0.08      0.24      0.12        80\n",
      "         303       0.08      0.06      0.07        80\n",
      "         304       0.08      0.90      0.14        80\n",
      "         305       0.00      0.00      0.00        80\n",
      "         306       0.00      0.00      0.00        80\n",
      "         307       0.00      0.00      0.00        80\n",
      "         308       0.00      0.00      0.00        80\n",
      "         309       0.00      0.00      0.00        80\n",
      "         310       0.08      0.05      0.06        80\n",
      "         311       0.00      0.00      0.00        80\n",
      "         312       0.00      0.00      0.00        80\n",
      "         313       0.00      0.00      0.00        80\n",
      "         314       0.00      0.00      0.00        80\n",
      "         315       0.00      0.00      0.00        80\n",
      "         400       0.00      0.00      0.00        80\n",
      "         401       0.14      0.04      0.06        80\n",
      "         402       0.00      0.00      0.00        80\n",
      "         403       0.25      0.01      0.02        80\n",
      "         404       0.00      0.00      0.00        80\n",
      "         405       0.17      0.01      0.02        80\n",
      "         406       0.14      0.19      0.16        80\n",
      "         407       0.12      1.00      0.22        80\n",
      "         408       0.00      0.00      0.00        80\n",
      "         409       0.00      0.00      0.00        80\n",
      "         500       0.00      0.00      0.00        80\n",
      "         501       0.00      0.00      0.00        80\n",
      "         502       0.00      0.00      0.00        80\n",
      "         503       0.00      0.00      0.00        80\n",
      "         504       0.08      0.01      0.02        80\n",
      "         505       0.00      0.00      0.00        80\n",
      "         506       0.07      0.23      0.11        80\n",
      "         507       0.00      0.00      0.00        80\n",
      "         508       0.00      0.00      0.00        80\n",
      "         509       0.00      0.00      0.00        80\n",
      "         510       0.00      0.00      0.00        80\n",
      "         511       0.08      0.05      0.06        80\n",
      "         512       0.07      0.96      0.13        80\n",
      "         513       0.00      0.00      0.00        80\n",
      "         514       0.00      0.00      0.00        80\n",
      "         515       0.00      0.00      0.00        80\n",
      "         516       0.00      0.00      0.00        80\n",
      "         517       0.00      0.00      0.00        80\n",
      "         600       0.12      0.05      0.07        80\n",
      "         601       0.00      0.00      0.00        80\n",
      "         602       0.00      0.00      0.00        80\n",
      "         603       0.10      0.91      0.18        80\n",
      "         604       0.11      0.28      0.15        80\n",
      "         605       0.00      0.00      0.00        80\n",
      "         606       0.00      0.00      0.00        80\n",
      "         607       0.00      0.00      0.00        80\n",
      "         608       0.00      0.00      0.00        80\n",
      "         609       0.12      0.01      0.02        80\n",
      "         610       0.00      0.00      0.00        80\n",
      "         611       0.00      0.00      0.00        80\n",
      "         700       0.14      1.00      0.24        80\n",
      "         701       0.00      0.00      0.00        80\n",
      "         702       0.00      0.00      0.00        80\n",
      "         703       0.18      0.03      0.04        80\n",
      "         704       0.00      0.00      0.00        80\n",
      "         705       0.17      0.04      0.06        80\n",
      "         706       0.15      0.17      0.16        80\n",
      "         707       0.00      0.00      0.00        80\n",
      "         708       0.20      0.01      0.02        80\n",
      "         800       0.00      0.00      0.00        80\n",
      "         801       0.00      0.00      0.00        80\n",
      "         802       0.00      0.00      0.00        80\n",
      "         803       0.00      0.00      0.00        80\n",
      "         804       0.00      0.00      0.00        80\n",
      "         805       0.07      0.09      0.08        80\n",
      "         806       0.09      0.03      0.04        80\n",
      "         807       0.00      0.00      0.00        80\n",
      "         808       0.00      0.00      0.00        80\n",
      "         809       0.07      0.90      0.13        80\n",
      "         810       0.00      0.00      0.00        80\n",
      "         811       0.00      0.00      0.00        80\n",
      "         812       0.00      0.00      0.00        80\n",
      "         813       0.00      0.00      0.00        80\n",
      "         814       0.00      0.00      0.00        80\n",
      "         815       0.07      0.17      0.10        80\n",
      "         816       0.08      0.06      0.07        80\n",
      "         817       0.00      0.00      0.00        80\n",
      "         900       0.00      0.00      0.00        80\n",
      "         901       0.00      0.00      0.00        80\n",
      "         902       0.09      0.01      0.02        80\n",
      "         903       0.00      0.00      0.00        80\n",
      "         904       0.08      0.21      0.11        80\n",
      "         905       0.00      0.00      0.00        80\n",
      "         906       0.00      0.00      0.00        80\n",
      "         907       0.00      0.00      0.00        80\n",
      "         908       0.00      0.00      0.00        80\n",
      "         909       0.00      0.00      0.00        80\n",
      "         910       0.00      0.00      0.00        80\n",
      "         911       0.00      0.00      0.00        80\n",
      "         912       0.00      0.00      0.00        80\n",
      "         913       0.07      0.97      0.13        80\n",
      "         914       0.00      0.00      0.00        80\n",
      "         915       0.08      0.05      0.06        80\n",
      "         916       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.03      0.09      0.03     11440\n",
      "weighted avg       0.03      0.09      0.03     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "train['gnb_predicted'] = gnb.predict(X_train)\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.gnb_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.gnb_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.gnb_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimoial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8.74%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          0   1   2   3   4   5   6   7   8   9  ...  907  908  909  \\\n",
      "mnb_predicted                                          ...                  \n",
      "0               5   3   4   4   3   4   4   5   5   4  ...    0    0    0   \n",
      "2               6   6   6   5   4   4   2   6   5   4  ...    0    0    0   \n",
      "3               7   7   5   8   8   8   6   5   7   6  ...    0    0    0   \n",
      "4              14  17  17  16  22  16  21  17  16  22  ...    0    0    0   \n",
      "5               1   1   1   0   0   1   1   1   1   1  ...    0    0    0   \n",
      "...            ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...   \n",
      "912             0   0   0   0   0   0   0   0   0   0  ...    1    2    2   \n",
      "913             0   0   0   0   0   0   0   0   0   0  ...   24   26   27   \n",
      "914             0   0   0   0   0   0   0   0   0   0  ...    1    1    1   \n",
      "915             0   0   0   0   0   0   0   0   0   0  ...    7    7    6   \n",
      "916             0   0   0   0   0   0   0   0   0   0  ...    2    2    2   \n",
      "\n",
      "actual         910  911  912  913  914  915  916  \n",
      "mnb_predicted                                     \n",
      "0                0    0    0    0    0    0    0  \n",
      "2                0    0    0    0    0    0    0  \n",
      "3                0    0    0    0    0    0    0  \n",
      "4                0    0    0    0    0    0    0  \n",
      "5                0    0    0    0    0    0    0  \n",
      "...            ...  ...  ...  ...  ...  ...  ...  \n",
      "912              2    2    2    0    1    2    2  \n",
      "913             25   24   24   31   23   24   22  \n",
      "914              1    1    1    1    1    1    1  \n",
      "915              5    4    6    5    4    7    6  \n",
      "916              2    2    2    2    2    2    3  \n",
      "\n",
      "[137 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.06      0.08        80\n",
      "           1       0.00      0.00      0.00        80\n",
      "           2       0.10      0.07      0.08        80\n",
      "           3       0.09      0.10      0.10        80\n",
      "           4       0.10      0.28      0.14        80\n",
      "           5       0.10      0.01      0.02        80\n",
      "           6       0.09      0.10      0.10        80\n",
      "           7       0.10      0.12      0.11        80\n",
      "           8       0.10      0.01      0.02        80\n",
      "           9       0.08      0.01      0.02        80\n",
      "          10       0.09      0.07      0.08        80\n",
      "          11       0.10      0.35      0.15        80\n",
      "          12       0.10      0.05      0.07        80\n",
      "         100       0.10      0.15      0.12        80\n",
      "         101       0.10      0.07      0.08        80\n",
      "         102       0.10      0.03      0.04        80\n",
      "         103       0.10      0.06      0.08        80\n",
      "         104       0.08      0.01      0.02        80\n",
      "         105       0.09      0.23      0.13        80\n",
      "         106       0.10      0.17      0.12        80\n",
      "         107       0.12      0.04      0.06        80\n",
      "         108       0.09      0.01      0.02        80\n",
      "         109       0.10      0.03      0.04        80\n",
      "         110       0.10      0.29      0.14        80\n",
      "         111       0.09      0.06      0.08        80\n",
      "         112       0.10      0.10      0.10        80\n",
      "         200       0.07      0.04      0.05        80\n",
      "         201       0.08      0.01      0.02        80\n",
      "         202       0.07      0.21      0.11        80\n",
      "         203       0.07      0.04      0.05        80\n",
      "         204       0.07      0.10      0.08        80\n",
      "         205       0.07      0.17      0.10        80\n",
      "         206       0.07      0.01      0.02        80\n",
      "         207       0.08      0.05      0.06        80\n",
      "         208       0.07      0.12      0.09        80\n",
      "         209       0.08      0.05      0.06        80\n",
      "         210       0.08      0.09      0.08        80\n",
      "         211       0.07      0.04      0.05        80\n",
      "         212       0.07      0.09      0.08        80\n",
      "         213       0.07      0.09      0.08        80\n",
      "         214       0.07      0.05      0.06        80\n",
      "         215       0.00      0.00      0.00        80\n",
      "         216       0.07      0.09      0.08        80\n",
      "         300       0.07      0.03      0.04        80\n",
      "         301       0.08      0.11      0.09        80\n",
      "         302       0.08      0.28      0.12        80\n",
      "         303       0.08      0.15      0.10        80\n",
      "         304       0.08      0.11      0.09        80\n",
      "         305       0.08      0.04      0.05        80\n",
      "         306       0.08      0.03      0.04        80\n",
      "         307       0.07      0.01      0.02        80\n",
      "         308       0.08      0.09      0.08        80\n",
      "         309       0.08      0.09      0.08        80\n",
      "         310       0.08      0.04      0.05        80\n",
      "         311       0.09      0.05      0.06        80\n",
      "         312       0.08      0.09      0.08        80\n",
      "         313       0.08      0.04      0.05        80\n",
      "         314       0.08      0.05      0.06        80\n",
      "         315       0.07      0.06      0.07        80\n",
      "         400       0.11      0.04      0.06        80\n",
      "         401       0.12      0.03      0.04        80\n",
      "         402       0.15      0.07      0.10        80\n",
      "         403       0.12      0.14      0.13        80\n",
      "         404       0.12      0.05      0.07        80\n",
      "         405       0.13      0.07      0.10        80\n",
      "         406       0.13      0.23      0.16        80\n",
      "         407       0.13      0.51      0.20        80\n",
      "         408       0.12      0.06      0.08        80\n",
      "         409       0.12      0.05      0.07        80\n",
      "         500       0.07      0.15      0.09        80\n",
      "         501       0.08      0.01      0.02        80\n",
      "         502       0.07      0.04      0.05        80\n",
      "         503       0.08      0.03      0.04        80\n",
      "         504       0.07      0.07      0.07        80\n",
      "         505       0.07      0.09      0.08        80\n",
      "         506       0.07      0.11      0.09        80\n",
      "         507       0.07      0.04      0.05        80\n",
      "         508       0.07      0.03      0.04        80\n",
      "         509       0.06      0.04      0.05        80\n",
      "         510       0.08      0.01      0.02        80\n",
      "         511       0.07      0.31      0.11        80\n",
      "         512       0.07      0.09      0.08        80\n",
      "         513       0.07      0.04      0.05        80\n",
      "         514       0.00      0.00      0.00        80\n",
      "         515       0.07      0.03      0.04        80\n",
      "         516       0.07      0.11      0.09        80\n",
      "         517       0.07      0.06      0.07        80\n",
      "         600       0.10      0.10      0.10        80\n",
      "         601       0.10      0.17      0.13        80\n",
      "         602       0.09      0.01      0.02        80\n",
      "         603       0.11      0.31      0.16        80\n",
      "         604       0.10      0.12      0.11        80\n",
      "         605       0.10      0.05      0.07        80\n",
      "         606       0.11      0.04      0.06        80\n",
      "         607       0.10      0.10      0.10        80\n",
      "         608       0.11      0.11      0.11        80\n",
      "         609       0.10      0.14      0.12        80\n",
      "         610       0.10      0.04      0.06        80\n",
      "         611       0.11      0.05      0.07        80\n",
      "         700       0.14      0.44      0.21        80\n",
      "         701       0.15      0.04      0.06        80\n",
      "         702       0.15      0.09      0.11        80\n",
      "         703       0.14      0.01      0.02        80\n",
      "         704       0.14      0.03      0.04        80\n",
      "         705       0.14      0.29      0.19        80\n",
      "         706       0.14      0.23      0.17        80\n",
      "         707       0.14      0.10      0.12        80\n",
      "         708       0.14      0.04      0.06        80\n",
      "         800       0.07      0.06      0.07        80\n",
      "         801       0.08      0.09      0.08        80\n",
      "         802       0.07      0.07      0.07        80\n",
      "         803       0.07      0.07      0.07        80\n",
      "         804       0.00      0.00      0.00        80\n",
      "         805       0.07      0.09      0.08        80\n",
      "         806       0.07      0.04      0.05        80\n",
      "         807       0.00      0.00      0.00        80\n",
      "         808       0.08      0.07      0.08        80\n",
      "         809       0.07      0.34      0.11        80\n",
      "         810       0.07      0.12      0.09        80\n",
      "         811       0.06      0.06      0.06        80\n",
      "         812       0.07      0.01      0.02        80\n",
      "         813       0.06      0.01      0.02        80\n",
      "         814       0.07      0.05      0.06        80\n",
      "         815       0.06      0.09      0.07        80\n",
      "         816       0.07      0.03      0.04        80\n",
      "         817       0.08      0.04      0.05        80\n",
      "         900       0.09      0.01      0.02        80\n",
      "         901       0.00      0.00      0.00        80\n",
      "         902       0.09      0.04      0.05        80\n",
      "         903       0.08      0.01      0.02        80\n",
      "         904       0.07      0.30      0.12        80\n",
      "         905       0.07      0.01      0.02        80\n",
      "         906       0.07      0.11      0.09        80\n",
      "         907       0.06      0.03      0.04        80\n",
      "         908       0.07      0.05      0.06        80\n",
      "         909       0.08      0.03      0.04        80\n",
      "         910       0.09      0.03      0.04        80\n",
      "         911       0.07      0.09      0.08        80\n",
      "         912       0.07      0.03      0.04        80\n",
      "         913       0.07      0.39      0.12        80\n",
      "         914       0.06      0.01      0.02        80\n",
      "         915       0.07      0.09      0.08        80\n",
      "         916       0.08      0.04      0.05        80\n",
      "\n",
      "    accuracy                           0.09     11440\n",
      "   macro avg       0.08      0.09      0.07     11440\n",
      "weighted avg       0.08      0.09      0.07     11440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Multinomial naive bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "train['mnb_predicted'] = mnb.predict(X_train)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.mnb_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.mnb_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.mnb_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>gnb_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9644</th>\n",
       "      <td>608</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>200</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13875</th>\n",
       "      <td>900</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>906</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>108</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>706</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>800</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>305</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  gnb_predicted\n",
       "9644     608            603\n",
       "3977     200            204\n",
       "13875    900            913\n",
       "14102    906            913\n",
       "296       10             11\n",
       "...      ...            ...\n",
       "1854     108            105\n",
       "10158    706            700\n",
       "2057     103            105\n",
       "10800    800            809\n",
       "5553     305            304\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11440"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[train.actual==train.knn_predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>gnb_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [actual, gnb_predicted]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.actual==test.gnb_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual          0   1   2   3   4   5   6   7   8   9  ...  907  908  909  \\\n",
      "gnb_predicted                                          ...                  \n",
      "6               5   3   4   1   2   5   0   6   1   2  ...    0    0    0   \n",
      "7               0   0   1   0   0   0   1   0   0   0  ...    0    0    0   \n",
      "10              1   0   0   1   1   0   3   1   0   0  ...    0    0    0   \n",
      "11             14  17  15  18  17  15  16  13  19  18  ...    0    0    0   \n",
      "101             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "105             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "111             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "112             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "204             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "205             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "213             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "302             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "303             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "304             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "310             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "401             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "403             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "405             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "406             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "407             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "504             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "506             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "511             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "512             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "600             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "603             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "604             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "609             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "700             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "703             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "705             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "706             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "708             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "805             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "806             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "809             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "815             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "816             0   0   0   0   0   0   0   0   0   0  ...    0    0    0   \n",
      "902             0   0   0   0   0   0   0   0   0   0  ...    0    0    1   \n",
      "904             0   0   0   0   0   0   0   0   0   0  ...    2    3    5   \n",
      "913             0   0   0   0   0   0   0   0   0   0  ...   17   16   14   \n",
      "915             0   0   0   0   0   0   0   0   0   0  ...    1    1    0   \n",
      "\n",
      "actual         910  911  912  913  914  915  916  \n",
      "gnb_predicted                                     \n",
      "6                0    0    0    0    0    0    0  \n",
      "7                0    0    0    0    0    0    0  \n",
      "10               0    0    0    0    0    0    0  \n",
      "11               0    0    0    0    0    0    0  \n",
      "101              0    0    0    0    0    0    0  \n",
      "105              0    0    0    0    0    0    0  \n",
      "111              0    0    0    0    0    0    0  \n",
      "112              0    0    0    0    0    0    0  \n",
      "204              0    0    0    0    0    0    0  \n",
      "205              0    0    0    0    0    0    0  \n",
      "213              0    0    0    0    0    0    0  \n",
      "302              0    0    0    0    0    0    0  \n",
      "303              0    0    0    0    0    0    0  \n",
      "304              0    0    0    0    0    0    0  \n",
      "310              0    0    0    0    0    0    0  \n",
      "401              0    0    0    0    0    0    0  \n",
      "403              0    0    0    0    0    0    0  \n",
      "405              0    0    0    0    0    0    0  \n",
      "406              0    0    0    0    0    0    0  \n",
      "407              0    0    0    0    0    0    0  \n",
      "504              0    0    0    0    0    0    0  \n",
      "506              0    0    0    0    0    0    0  \n",
      "511              0    0    0    0    0    0    0  \n",
      "512              0    0    0    0    0    0    0  \n",
      "600              0    0    0    0    0    0    0  \n",
      "603              0    0    0    0    0    0    0  \n",
      "604              0    0    0    0    0    0    0  \n",
      "609              0    0    0    0    0    0    0  \n",
      "700              0    0    0    0    0    0    0  \n",
      "703              0    0    0    0    0    0    0  \n",
      "705              0    0    0    0    0    0    0  \n",
      "706              0    0    0    0    0    0    0  \n",
      "708              0    0    0    0    0    0    0  \n",
      "805              0    0    0    0    0    0    0  \n",
      "806              0    0    0    0    0    0    0  \n",
      "809              0    0    0    0    0    0    0  \n",
      "815              0    0    0    0    0    0    0  \n",
      "816              0    0    0    0    0    0    0  \n",
      "902              1    0    0    1    0    1    0  \n",
      "904              3    3    5   15    3    4    3  \n",
      "913             14   17   14    0   16   15   16  \n",
      "915              2    0    1    4    1    0    1  \n",
      "\n",
      "[42 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      20.0\n",
      "           1       0.00      0.00      0.00      20.0\n",
      "           2       0.00      0.00      0.00      20.0\n",
      "           3       0.00      0.00      0.00      20.0\n",
      "           4       0.00      0.00      0.00      20.0\n",
      "           5       0.00      0.00      0.00      20.0\n",
      "           6       0.00      0.00      0.00      20.0\n",
      "           7       0.00      0.00      0.00      20.0\n",
      "           8       0.00      0.00      0.00      20.0\n",
      "           9       0.00      0.00      0.00      20.0\n",
      "          10       0.00      0.00      0.00      20.0\n",
      "          11       0.00      0.00      0.00      20.0\n",
      "          12       0.00      0.00      0.00      20.0\n",
      "         100       0.00      0.00      0.00      20.0\n",
      "         101       0.00      0.00      0.00      20.0\n",
      "         102       0.00      0.00      0.00      20.0\n",
      "         103       0.00      0.00      0.00      20.0\n",
      "         104       0.00      0.00      0.00      20.0\n",
      "         105       0.00      0.00      0.00      20.0\n",
      "         106       0.00      0.00      0.00      20.0\n",
      "         107       0.00      0.00      0.00      20.0\n",
      "         108       0.00      0.00      0.00      20.0\n",
      "         109       0.00      0.00      0.00      20.0\n",
      "         110       0.00      0.00      0.00      20.0\n",
      "         111       0.00      0.00      0.00      20.0\n",
      "         112       0.00      0.00      0.00      20.0\n",
      "         200       0.00      0.00      0.00      20.0\n",
      "         201       0.00      0.00      0.00      20.0\n",
      "         202       0.00      0.00      0.00      20.0\n",
      "         203       0.00      0.00      0.00      20.0\n",
      "         204       0.00      0.00      0.00      20.0\n",
      "         205       0.00      0.00      0.00      20.0\n",
      "         206       0.00      0.00      0.00      20.0\n",
      "         207       0.00      0.00      0.00      20.0\n",
      "         208       0.00      0.00      0.00      20.0\n",
      "         209       0.00      0.00      0.00      20.0\n",
      "         210       0.00      0.00      0.00      20.0\n",
      "         211       0.00      0.00      0.00      20.0\n",
      "         212       0.00      0.00      0.00      20.0\n",
      "         213       0.00      0.00      0.00      20.0\n",
      "         214       0.00      0.00      0.00      20.0\n",
      "         215       0.00      0.00      0.00      20.0\n",
      "         216       0.00      0.00      0.00      20.0\n",
      "         300       0.00      0.00      0.00      20.0\n",
      "         301       0.00      0.00      0.00      20.0\n",
      "         302       0.00      0.00      0.00      20.0\n",
      "         303       0.00      0.00      0.00      20.0\n",
      "         304       0.00      0.00      0.00      20.0\n",
      "         305       0.00      0.00      0.00      20.0\n",
      "         306       0.00      0.00      0.00      20.0\n",
      "         307       0.00      0.00      0.00      20.0\n",
      "         308       0.00      0.00      0.00      20.0\n",
      "         309       0.00      0.00      0.00      20.0\n",
      "         310       0.00      0.00      0.00      20.0\n",
      "         311       0.00      0.00      0.00      20.0\n",
      "         312       0.00      0.00      0.00      20.0\n",
      "         313       0.00      0.00      0.00      20.0\n",
      "         314       0.00      0.00      0.00      20.0\n",
      "         315       0.00      0.00      0.00      20.0\n",
      "         400       0.00      0.00      0.00      20.0\n",
      "         401       0.00      0.00      0.00      20.0\n",
      "         402       0.00      0.00      0.00      20.0\n",
      "         403       0.00      0.00      0.00      20.0\n",
      "         404       0.00      0.00      0.00      20.0\n",
      "         405       0.00      0.00      0.00      20.0\n",
      "         406       0.00      0.00      0.00      20.0\n",
      "         407       0.00      0.00      0.00      20.0\n",
      "         408       0.00      0.00      0.00      20.0\n",
      "         409       0.00      0.00      0.00      20.0\n",
      "         500       0.00      0.00      0.00      20.0\n",
      "         501       0.00      0.00      0.00      20.0\n",
      "         502       0.00      0.00      0.00      20.0\n",
      "         503       0.00      0.00      0.00      20.0\n",
      "         504       0.00      0.00      0.00      20.0\n",
      "         505       0.00      0.00      0.00      20.0\n",
      "         506       0.00      0.00      0.00      20.0\n",
      "         507       0.00      0.00      0.00      20.0\n",
      "         508       0.00      0.00      0.00      20.0\n",
      "         509       0.00      0.00      0.00      20.0\n",
      "         510       0.00      0.00      0.00      20.0\n",
      "         511       0.00      0.00      0.00      20.0\n",
      "         512       0.00      0.00      0.00      20.0\n",
      "         513       0.00      0.00      0.00      20.0\n",
      "         514       0.00      0.00      0.00      20.0\n",
      "         515       0.00      0.00      0.00      20.0\n",
      "         516       0.00      0.00      0.00      20.0\n",
      "         517       0.00      0.00      0.00      20.0\n",
      "         600       0.00      0.00      0.00      20.0\n",
      "         601       0.00      0.00      0.00      20.0\n",
      "         602       0.00      0.00      0.00      20.0\n",
      "         603       0.00      0.00      0.00      20.0\n",
      "         604       0.00      0.00      0.00      20.0\n",
      "         605       0.00      0.00      0.00      20.0\n",
      "         606       0.00      0.00      0.00      20.0\n",
      "         607       0.00      0.00      0.00      20.0\n",
      "         608       0.00      0.00      0.00      20.0\n",
      "         609       0.00      0.00      0.00      20.0\n",
      "         610       0.00      0.00      0.00      20.0\n",
      "         611       0.00      0.00      0.00      20.0\n",
      "         700       0.00      0.00      0.00      20.0\n",
      "         701       0.00      0.00      0.00      20.0\n",
      "         702       0.00      0.00      0.00      20.0\n",
      "         703       0.00      0.00      0.00      20.0\n",
      "         704       0.00      0.00      0.00      20.0\n",
      "         705       0.00      0.00      0.00      20.0\n",
      "         706       0.00      0.00      0.00      20.0\n",
      "         707       0.00      0.00      0.00      20.0\n",
      "         708       0.00      0.00      0.00      20.0\n",
      "         800       0.00      0.00      0.00      20.0\n",
      "         801       0.00      0.00      0.00      20.0\n",
      "         802       0.00      0.00      0.00      20.0\n",
      "         803       0.00      0.00      0.00      20.0\n",
      "         804       0.00      0.00      0.00      20.0\n",
      "         805       0.00      0.00      0.00      20.0\n",
      "         806       0.00      0.00      0.00      20.0\n",
      "         807       0.00      0.00      0.00      20.0\n",
      "         808       0.00      0.00      0.00      20.0\n",
      "         809       0.00      0.00      0.00      20.0\n",
      "         810       0.00      0.00      0.00      20.0\n",
      "         811       0.00      0.00      0.00      20.0\n",
      "         812       0.00      0.00      0.00      20.0\n",
      "         813       0.00      0.00      0.00      20.0\n",
      "         814       0.00      0.00      0.00      20.0\n",
      "         815       0.00      0.00      0.00      20.0\n",
      "         816       0.00      0.00      0.00      20.0\n",
      "         817       0.00      0.00      0.00      20.0\n",
      "         900       0.00      0.00      0.00      20.0\n",
      "         901       0.00      0.00      0.00      20.0\n",
      "         902       0.00      0.00      0.00      20.0\n",
      "         903       0.00      0.00      0.00      20.0\n",
      "         904       0.00      0.00      0.00      20.0\n",
      "         905       0.00      0.00      0.00      20.0\n",
      "         906       0.00      0.00      0.00      20.0\n",
      "         907       0.00      0.00      0.00      20.0\n",
      "         908       0.00      0.00      0.00      20.0\n",
      "         909       0.00      0.00      0.00      20.0\n",
      "         910       0.00      0.00      0.00      20.0\n",
      "         911       0.00      0.00      0.00      20.0\n",
      "         912       0.00      0.00      0.00      20.0\n",
      "         913       0.00      0.00      0.00      20.0\n",
      "         914       0.00      0.00      0.00      20.0\n",
      "         915       0.00      0.00      0.00      20.0\n",
      "         916       0.00      0.00      0.00      20.0\n",
      "\n",
      "    accuracy                           0.00    2860.0\n",
      "   macro avg       0.00      0.00      0.00    2860.0\n",
      "weighted avg       0.00      0.00      0.00    2860.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create testing dataframe\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "test['gnb_predicted'] = gnb.predict(X_test)\n",
    "# Evaluate model\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.gnb_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.gnb_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.gnb_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4936     312\n",
       "4107     211\n",
       "10080    700\n",
       "9886     610\n",
       "3720     215\n",
       "        ... \n",
       "10250    708\n",
       "12688    903\n",
       "4666     314\n",
       "13035    910\n",
       "5615     303\n",
       "Name: feature_num, Length: 2860, dtype: category\n",
       "Categories (143, int64): [0, 1, 2, 3, ..., 913, 914, 915, 916]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         0  1   2  3  4  5  6  7  8  9  ...  907  908  909  910  911  \\\n",
      "knn_predicted                                 ...                            \n",
      "0              0  6  10  7  7  8  8  9  7  7  ...    0    0    0    0    0   \n",
      "1              8  0   0  6  7  7  7  3  5  6  ...    0    0    0    0    0   \n",
      "2              3  4   0  5  3  1  2  2  3  2  ...    0    0    0    0    0   \n",
      "3              4  4   4  0  2  2  0  3  1  3  ...    0    0    0    0    0   \n",
      "4              2  3   1  0  0  1  0  1  3  2  ...    0    0    0    0    0   \n",
      "...           .. ..  .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...   \n",
      "904            0  0   0  0  0  0  0  0  0  0  ...    3    2    1    3    4   \n",
      "905            0  0   0  0  0  0  0  0  0  0  ...    2    2    1    0    1   \n",
      "906            0  0   0  0  0  0  0  0  0  0  ...    1    0    0    2    1   \n",
      "907            0  0   0  0  0  0  0  0  0  0  ...    0    0    0    0    1   \n",
      "908            0  0   0  0  0  0  0  0  0  0  ...    1    0    0    1    1   \n",
      "\n",
      "actual         912  913  914  915  916  \n",
      "knn_predicted                           \n",
      "0                0    0    0    0    0  \n",
      "1                0    0    0    0    0  \n",
      "2                0    0    0    0    0  \n",
      "3                0    0    0    0    0  \n",
      "4                0    0    0    0    0  \n",
      "...            ...  ...  ...  ...  ...  \n",
      "904              2    1    2    1    2  \n",
      "905              1    2    3    1    1  \n",
      "906              3    2    4    2    3  \n",
      "907              1    1    2    0    0  \n",
      "908              0    0    0    1    1  \n",
      "\n",
      "[89 rows x 143 columns]\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      20.0\n",
      "           1       0.00      0.00      0.00      20.0\n",
      "           2       0.00      0.00      0.00      20.0\n",
      "           3       0.00      0.00      0.00      20.0\n",
      "           4       0.00      0.00      0.00      20.0\n",
      "           5       0.00      0.00      0.00      20.0\n",
      "           6       0.00      0.00      0.00      20.0\n",
      "           7       0.00      0.00      0.00      20.0\n",
      "           8       0.00      0.00      0.00      20.0\n",
      "           9       0.00      0.00      0.00      20.0\n",
      "          10       0.00      0.00      0.00      20.0\n",
      "          11       0.00      0.00      0.00      20.0\n",
      "          12       0.00      0.00      0.00      20.0\n",
      "         100       0.00      0.00      0.00      20.0\n",
      "         101       0.00      0.00      0.00      20.0\n",
      "         102       0.00      0.00      0.00      20.0\n",
      "         103       0.00      0.00      0.00      20.0\n",
      "         104       0.00      0.00      0.00      20.0\n",
      "         105       0.00      0.00      0.00      20.0\n",
      "         106       0.00      0.00      0.00      20.0\n",
      "         107       0.00      0.00      0.00      20.0\n",
      "         108       0.00      0.00      0.00      20.0\n",
      "         109       0.00      0.00      0.00      20.0\n",
      "         110       0.00      0.00      0.00      20.0\n",
      "         111       0.00      0.00      0.00      20.0\n",
      "         112       0.00      0.00      0.00      20.0\n",
      "         200       0.00      0.00      0.00      20.0\n",
      "         201       0.00      0.00      0.00      20.0\n",
      "         202       0.00      0.00      0.00      20.0\n",
      "         203       0.00      0.00      0.00      20.0\n",
      "         204       0.00      0.00      0.00      20.0\n",
      "         205       0.00      0.00      0.00      20.0\n",
      "         206       0.00      0.00      0.00      20.0\n",
      "         207       0.00      0.00      0.00      20.0\n",
      "         208       0.00      0.00      0.00      20.0\n",
      "         209       0.00      0.00      0.00      20.0\n",
      "         210       0.00      0.00      0.00      20.0\n",
      "         211       0.00      0.00      0.00      20.0\n",
      "         212       0.00      0.00      0.00      20.0\n",
      "         213       0.00      0.00      0.00      20.0\n",
      "         214       0.00      0.00      0.00      20.0\n",
      "         215       0.00      0.00      0.00      20.0\n",
      "         216       0.00      0.00      0.00      20.0\n",
      "         300       0.00      0.00      0.00      20.0\n",
      "         301       0.00      0.00      0.00      20.0\n",
      "         302       0.00      0.00      0.00      20.0\n",
      "         303       0.00      0.00      0.00      20.0\n",
      "         304       0.00      0.00      0.00      20.0\n",
      "         305       0.00      0.00      0.00      20.0\n",
      "         306       0.00      0.00      0.00      20.0\n",
      "         307       0.00      0.00      0.00      20.0\n",
      "         308       0.00      0.00      0.00      20.0\n",
      "         309       0.00      0.00      0.00      20.0\n",
      "         310       0.00      0.00      0.00      20.0\n",
      "         311       0.00      0.00      0.00      20.0\n",
      "         312       0.00      0.00      0.00      20.0\n",
      "         313       0.00      0.00      0.00      20.0\n",
      "         314       0.00      0.00      0.00      20.0\n",
      "         315       0.00      0.00      0.00      20.0\n",
      "         400       0.00      0.00      0.00      20.0\n",
      "         401       0.00      0.00      0.00      20.0\n",
      "         402       0.00      0.00      0.00      20.0\n",
      "         403       0.00      0.00      0.00      20.0\n",
      "         404       0.00      0.00      0.00      20.0\n",
      "         405       0.00      0.00      0.00      20.0\n",
      "         406       0.00      0.00      0.00      20.0\n",
      "         407       0.00      0.00      0.00      20.0\n",
      "         408       0.00      0.00      0.00      20.0\n",
      "         409       0.00      0.00      0.00      20.0\n",
      "         500       0.00      0.00      0.00      20.0\n",
      "         501       0.00      0.00      0.00      20.0\n",
      "         502       0.00      0.00      0.00      20.0\n",
      "         503       0.00      0.00      0.00      20.0\n",
      "         504       0.00      0.00      0.00      20.0\n",
      "         505       0.00      0.00      0.00      20.0\n",
      "         506       0.00      0.00      0.00      20.0\n",
      "         507       0.00      0.00      0.00      20.0\n",
      "         508       0.00      0.00      0.00      20.0\n",
      "         509       0.00      0.00      0.00      20.0\n",
      "         510       0.00      0.00      0.00      20.0\n",
      "         511       0.00      0.00      0.00      20.0\n",
      "         512       0.00      0.00      0.00      20.0\n",
      "         513       0.00      0.00      0.00      20.0\n",
      "         514       0.00      0.00      0.00      20.0\n",
      "         515       0.00      0.00      0.00      20.0\n",
      "         516       0.00      0.00      0.00      20.0\n",
      "         517       0.00      0.00      0.00      20.0\n",
      "         600       0.00      0.00      0.00      20.0\n",
      "         601       0.00      0.00      0.00      20.0\n",
      "         602       0.00      0.00      0.00      20.0\n",
      "         603       0.00      0.00      0.00      20.0\n",
      "         604       0.00      0.00      0.00      20.0\n",
      "         605       0.00      0.00      0.00      20.0\n",
      "         606       0.00      0.00      0.00      20.0\n",
      "         607       0.00      0.00      0.00      20.0\n",
      "         608       0.00      0.00      0.00      20.0\n",
      "         609       0.00      0.00      0.00      20.0\n",
      "         610       0.00      0.00      0.00      20.0\n",
      "         611       0.00      0.00      0.00      20.0\n",
      "         700       0.00      0.00      0.00      20.0\n",
      "         701       0.00      0.00      0.00      20.0\n",
      "         702       0.00      0.00      0.00      20.0\n",
      "         703       0.00      0.00      0.00      20.0\n",
      "         704       0.00      0.00      0.00      20.0\n",
      "         705       0.00      0.00      0.00      20.0\n",
      "         706       0.00      0.00      0.00      20.0\n",
      "         707       0.00      0.00      0.00      20.0\n",
      "         708       0.00      0.00      0.00      20.0\n",
      "         800       0.00      0.00      0.00      20.0\n",
      "         801       0.00      0.00      0.00      20.0\n",
      "         802       0.00      0.00      0.00      20.0\n",
      "         803       0.00      0.00      0.00      20.0\n",
      "         804       0.00      0.00      0.00      20.0\n",
      "         805       0.00      0.00      0.00      20.0\n",
      "         806       0.00      0.00      0.00      20.0\n",
      "         807       0.00      0.00      0.00      20.0\n",
      "         808       0.00      0.00      0.00      20.0\n",
      "         809       0.00      0.00      0.00      20.0\n",
      "         810       0.00      0.00      0.00      20.0\n",
      "         811       0.00      0.00      0.00      20.0\n",
      "         812       0.00      0.00      0.00      20.0\n",
      "         813       0.00      0.00      0.00      20.0\n",
      "         814       0.00      0.00      0.00      20.0\n",
      "         815       0.00      0.00      0.00      20.0\n",
      "         816       0.00      0.00      0.00      20.0\n",
      "         817       0.00      0.00      0.00      20.0\n",
      "         900       0.00      0.00      0.00      20.0\n",
      "         901       0.00      0.00      0.00      20.0\n",
      "         902       0.00      0.00      0.00      20.0\n",
      "         903       0.00      0.00      0.00      20.0\n",
      "         904       0.00      0.00      0.00      20.0\n",
      "         905       0.00      0.00      0.00      20.0\n",
      "         906       0.00      0.00      0.00      20.0\n",
      "         907       0.00      0.00      0.00      20.0\n",
      "         908       0.00      0.00      0.00      20.0\n",
      "         909       0.00      0.00      0.00      20.0\n",
      "         910       0.00      0.00      0.00      20.0\n",
      "         911       0.00      0.00      0.00      20.0\n",
      "         912       0.00      0.00      0.00      20.0\n",
      "         913       0.00      0.00      0.00      20.0\n",
      "         914       0.00      0.00      0.00      20.0\n",
      "         915       0.00      0.00      0.00      20.0\n",
      "         916       0.00      0.00      0.00      20.0\n",
      "\n",
      "    accuracy                           0.00    2860.0\n",
      "   macro avg       0.00      0.00      0.00    2860.0\n",
      "weighted avg       0.00      0.00      0.00    2860.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create testing dataframe\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "test['knn_predicted'] = knn.predict(X_test)\n",
    "# Evaluate model\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.knn_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 8.74% accuracy represent a 1148.57% improvement from baseline\n"
     ]
    }
   ],
   "source": [
    "# Calculate percent improvement from baseline accuracy (.67%)\n",
    "pct_improvement = round(((8.74-0.70)/(0.70)*100), 2)\n",
    "print(f'Our 8.74% accuracy represent a {pct_improvement}% improvement from baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d66913bb719389121bab79020f7a52c6e05d87274bae621f301af382c19c893"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
